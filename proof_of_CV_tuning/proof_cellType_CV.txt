 For train set, picked 27 patients out of 34 patients with cancerous cells
- For train set, picked 21 patients out of 26 patients with non cancerous cells
- Therefore, there is a ratio of cancerous to total patients in train set of 0.5625 
- Therefore, there is a ratio of cancerous to total patients in test set of 0.5833333333333334 
- For fold set 0, picked 27 patients out of 27 train set patients with cancerous cells
- For fold set 0, picked 21 patients out of 21 train set patients with non cancerous cells
- Therefore, there is a ratio of cancerous to total patient in fold set 0 of 0.5625
- For fold set 1, picked 18 patients out of 27 train set patients with cancerous cells
- For fold set 1, picked 14 patients out of 21 train set patients with non cancerous cells
- Therefore, there is a ratio of cancerous to total patient in fold set 1 of 0.5625
- For fold set 2, picked 9 patients out of 27 train set patients with cancerous cells
- For fold set 2, picked 7 patients out of 21 train set patients with non cancerous cells
- Therefore, there is a ratio of cancerous to total patient in fold set 2 of 0.5625
Adding isCancerous: patient:6 to fold 0
Adding isCancerous: patient:7 to fold 1
Adding isCancerous: patient:8 to fold 2
Adding isCancerous: patient:9 to fold 0
Adding isCancerous: patient:10 to fold 1
Adding isCancerous: patient:13 to fold 0
Adding isCancerous: patient:14 to fold 2
Adding isCancerous: patient:17 to fold 0
Adding isCancerous: patient:19 to fold 2
Adding isCancerous: patient:20 to fold 2
Adding isCancerous: patient:21 to fold 1
Adding isCancerous: patient:22 to fold 0
Adding isCancerous: patient:30 to fold 0
Adding isCancerous: patient:32 to fold 2
Adding isCancerous: patient:38 to fold 1
Adding isCancerous: patient:40 to fold 0
Adding isCancerous: patient:41 to fold 2
Adding isCancerous: patient:42 to fold 0
Adding isCancerous: patient:43 to fold 1
Adding isCancerous: patient:46 to fold 1
Adding isCancerous: patient:47 to fold 1
Adding isCancerous: patient:49 to fold 2
Adding isCancerous: patient:52 to fold 1
Adding isCancerous: patient:53 to fold 2
Adding isCancerous: patient:54 to fold 1
Adding isCancerous: patient:55 to fold 2
Adding isCancerous: patient:60 to fold 0
Adding NonCancerous: patient2 to fold 2
Adding NonCancerous: patient3 to fold 0
Adding NonCancerous: patient4 to fold 2
Adding NonCancerous: patient12 to fold 1
Adding NonCancerous: patient15 to fold 0
Adding NonCancerous: patient16 to fold 2
Adding NonCancerous: patient23 to fold 1
Adding NonCancerous: patient25 to fold 1
Adding NonCancerous: patient26 to fold 2
Adding NonCancerous: patient27 to fold 1
Adding NonCancerous: patient28 to fold 1
Adding NonCancerous: patient29 to fold 2
Adding NonCancerous: patient34 to fold 2
Adding NonCancerous: patient37 to fold 0
Adding NonCancerous: patient39 to fold 2
Adding NonCancerous: patient44 to fold 0
Adding NonCancerous: patient45 to fold 1
Adding NonCancerous: patient56 to fold 0
Adding NonCancerous: patient57 to fold 0
Adding NonCancerous: patient58 to fold 0
Adding NonCancerous: patient59 to fold 1
- There is 16 patients in the fold set 0. The count for each cell type is:
cellType
2    1079
1     680
0     669
3     185
Name: count, dtype: int64
- There is 16 patients in the fold set 1. The count for each cell type is:
cellType
2    974
0    651
3    491
1    489
Name: count, dtype: int64
- There is 16 patients in the fold set 2. The count for each cell type is:
cellType
2    1130
1     957
3     412
0     356
Name: count, dtype: int64
- There is 39 patients in the train set.
- There is 12 patients in the test set. The count for each cell type is:
cellType
2    896
1    417
3    298
0    212
Name: count, dtype: int64
- Therefore, ratio of train to total is: 0.815784155214228 versus the ratio of test to total: 0.18421584478577202
- Therefore, ratio of fold set 0 to train is: 0.32367149758454106, and the ratio of fold set 0 to total is: 0.26404607922392886
- Therefore, ratio of fold set 1 to train is: 0.32268054007184443, and the ratio of fold set 1 to total is: 0.2632376717865804
- Therefore, ratio of fold set 2 to train is: 0.3536479623436145, and the ratio of fold set 2 to total is: 0.2885004042037187
- The value counts for isCancerous for fold set 0 is:
isCancerous
0    1534
1    1079
Name: count, dtype: int64
- The value counts for isCancerous for fold set 1 is:
isCancerous
0    1631
1     974
Name: count, dtype: int64
- The value counts for isCancerous for fold set 2 is:
isCancerous
0    1725
1    1130
Name: count, dtype: int64
- The value counts for isCancerous for train set is:
3183
- The value counts for isCancerous for test set is:
isCancerous
0    927
1    896
Name: count, dtype: int64
- The value counts for isCancerous for whole data set is:
isCancerous
0    5817
1    4079
Name: count, dtype: int64
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 34ms/step - f1: 0.1633 - loss: 2.3564 - val_f1: 0.0139 - val_loss: 1.4481
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 36ms/step - f1: 0.1330 - loss: 2.2991 - val_f1: 0.1291 - val_loss: 1.4176
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - f1: 0.1404 - loss: 2.3045
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1304 - loss: 2.2118 - val_f1: 0.1374 - val_loss: 1.4093
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.2492 - loss: 2.2599 - val_f1: 0.2213 - val_loss: 1.3794
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.3015 - loss: 2.2674 - val_f1: 0.1283 - val_loss: 1.4053
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1778 - loss: 2.2319 - val_f1: 0.1494 - val_loss: 1.4066
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.2528 - loss: 2.2427 - val_f1: 0.3035 - val_loss: 1.2944
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4000 - loss: 2.1696 - val_f1: 0.2495 - val_loss: 1.3171
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.3744 - loss: 2.2341 - val_f1: 0.2760 - val_loss: 1.3394
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4522 - loss: 1.9820 - val_f1: 0.5038 - val_loss: 1.2505
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4931 - loss: 1.9259 - val_f1: 0.4294 - val_loss: 1.3395
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5088 - loss: 2.0612 - val_f1: 0.4876 - val_loss: 1.2359
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4686 - loss: 1.9776 - val_f1: 0.3246 - val_loss: 1.2761
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4431 - loss: 1.9664 - val_f1: 0.4616 - val_loss: 1.2049
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5567 - loss: 1.7326 - val_f1: 0.4882 - val_loss: 1.1863
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5249 - loss: 1.8899 - val_f1: 0.6116 - val_loss: 1.0692
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4983 - loss: 1.9213 - val_f1: 0.4468 - val_loss: 1.1888
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.5849 - loss: 1.6036 - val_f1: 0.6396 - val_loss: 0.9989
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.5613 - loss: 1.8437 - val_f1: 0.5959 - val_loss: 1.0583
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.5062 - loss: 1.9301 - val_f1: 0.3569 - val_loss: 1.2289
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - f1: 0.3714 - loss: 1.9689
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 29ms/step - f1: 0.5424 - loss: 1.7758 - val_f1: 0.4871 - val_loss: 1.1608
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 5s 49ms/step - f1: 0.6046 - loss: 1.6196 - val_f1: 0.4138 - val_loss: 1.2084
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.5272 - loss: 1.4795
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.5605 - loss: 1.5359 - val_f1: 0.4440 - val_loss: 1.1916
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6319 - loss: 1.5932 - val_f1: 0.5661 - val_loss: 1.0213
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.6340 - loss: 1.5834 - val_f1: 0.5023 - val_loss: 1.1504
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6691 - loss: 1.3814 - val_f1: 0.5479 - val_loss: 1.0048
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6503 - loss: 1.5232 - val_f1: 0.5408 - val_loss: 1.0254
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6542 - loss: 1.5274 - val_f1: 0.5180 - val_loss: 1.0954
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6285 - loss: 1.5265 - val_f1: 0.5260 - val_loss: 1.0404
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6466 - loss: 1.5062 - val_f1: 0.5055 - val_loss: 1.1103
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6255 - loss: 1.5545 - val_f1: 0.5505 - val_loss: 1.0395
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6391 - loss: 1.4182 - val_f1: 0.5158 - val_loss: 0.9949
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.6343 - loss: 1.5205 - val_f1: 0.5181 - val_loss: 1.1605
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.6447 - loss: 1.5071 - val_f1: 0.5797 - val_loss: 0.9407
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7006 - loss: 1.4138 - val_f1: 0.5662 - val_loss: 0.9744
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6574 - loss: 1.4606 - val_f1: 0.5425 - val_loss: 1.0627
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6645 - loss: 1.4351 - val_f1: 0.5623 - val_loss: 0.9823
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7312 - loss: 1.3338 - val_f1: 0.5612 - val_loss: 0.9775
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.6809 - loss: 1.4078 - val_f1: 0.5781 - val_loss: 0.9926
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6728 - loss: 1.4476 - val_f1: 0.5650 - val_loss: 0.9214
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.5857 - loss: 1.8574
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 36ms/step - f1: 0.6005 - loss: 1.6628 - val_f1: 0.7056 - val_loss: 0.8457
Epoch 2/20
 92/100 ━━━━━━━━━━━━━━━━━━━━ 0s 45ms/step - f1: 0.6090 - loss: 1.6699
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 5s 48ms/step - f1: 0.6085 - loss: 1.6684 - val_f1: 0.7176 - val_loss: 0.7297
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 24ms/step - f1: 0.6162 - loss: 1.6036 - val_f1: 0.6911 - val_loss: 0.6967
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6228 - loss: 1.5513 - val_f1: 0.7087 - val_loss: 0.7456
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6123 - loss: 1.6201 - val_f1: 0.7078 - val_loss: 0.7147
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6531 - loss: 1.4860 - val_f1: 0.6933 - val_loss: 0.7205
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 25ms/step - f1: 0.6471 - loss: 1.5365 - val_f1: 0.7225 - val_loss: 0.7812
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6509 - loss: 1.5204 - val_f1: 0.6966 - val_loss: 0.8191
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6506 - loss: 1.5020 - val_f1: 0.7245 - val_loss: 0.7954
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 24ms/step - f1: 0.6574 - loss: 1.5309 - val_f1: 0.6880 - val_loss: 0.7069
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6757 - loss: 1.4555 - val_f1: 0.6993 - val_loss: 0.7688
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6424 - loss: 1.5262 - val_f1: 0.6680 - val_loss: 0.7948
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6669 - loss: 1.4752 - val_f1: 0.7135 - val_loss: 0.7716
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6753 - loss: 1.4558 - val_f1: 0.7106 - val_loss: 0.7537
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6695 - loss: 1.4335 - val_f1: 0.7010 - val_loss: 0.7606
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6642 - loss: 1.5083 - val_f1: 0.7197 - val_loss: 0.7490
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6738 - loss: 1.4768 - val_f1: 0.6928 - val_loss: 0.8051
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6641 - loss: 1.4595 - val_f1: 0.6940 - val_loss: 0.7766
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6931 - loss: 1.4201 - val_f1: 0.6770 - val_loss: 0.7752
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6995 - loss: 1.3949 - val_f1: 0.7147 - val_loss: 0.7262
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/tmp/ipykernel_18175/1384446587.py:66: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  val_scores = pd.concat([val_scores, new], ignore_index=True)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 37ms/step - f1: 0.1875 - loss: 2.3355 - val_f1: 0.0094 - val_loss: 1.4174
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 35ms/step - f1: 0.1085 - loss: 2.2979 - val_f1: 0.1075 - val_loss: 1.4277
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - f1: 0.0808 - loss: 2.5750
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0807 - loss: 2.3794 - val_f1: 0.1075 - val_loss: 1.4256
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1387 - loss: 2.3057 - val_f1: 0.1075 - val_loss: 1.4944
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1249 - loss: 2.2876 - val_f1: 0.1245 - val_loss: 1.4045
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1937 - loss: 2.2543 - val_f1: 0.2414 - val_loss: 1.4012
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.2745 - loss: 2.2716 - val_f1: 0.2414 - val_loss: 1.3656
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.2120 - loss: 2.3111 - val_f1: 0.1347 - val_loss: 1.4587
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1290 - loss: 2.3303 - val_f1: 0.0094 - val_loss: 1.4436
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1649 - loss: 2.3045 - val_f1: 0.1075 - val_loss: 1.4240
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1488 - loss: 2.2955 - val_f1: 0.0094 - val_loss: 1.5479
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0651 - loss: 2.4022 - val_f1: 0.0094 - val_loss: 1.5243
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.0624 - loss: 2.2978 - val_f1: 0.0094 - val_loss: 1.4456
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1306 - loss: 2.2944 - val_f1: 0.1075 - val_loss: 1.4410
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1457 - loss: 2.3704 - val_f1: 0.1075 - val_loss: 1.4407
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1168 - loss: 2.2807 - val_f1: 0.0094 - val_loss: 1.4519
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1348 - loss: 2.3252 - val_f1: 0.1075 - val_loss: 1.4239
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.0994 - loss: 2.3666 - val_f1: 0.1075 - val_loss: 1.4209
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1426 - loss: 2.3192 - val_f1: 0.1075 - val_loss: 1.4278
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1062 - loss: 2.2678 - val_f1: 0.1075 - val_loss: 1.4294
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.1244 - loss: 2.1164
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 41ms/step - f1: 0.1395 - loss: 2.1577 - val_f1: 0.0593 - val_loss: 1.4074
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1411 - loss: 2.1854 - val_f1: 0.0593 - val_loss: 1.4244
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - f1: 0.0808 - loss: 2.4868
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.1157 - loss: 2.3779 - val_f1: 0.0593 - val_loss: 1.4230
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.1396 - loss: 2.1735 - val_f1: 0.0593 - val_loss: 1.4208
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1376 - loss: 2.2074 - val_f1: 0.0593 - val_loss: 1.4285
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.1552 - loss: 2.2008 - val_f1: 0.0593 - val_loss: 1.4301
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1331 - loss: 2.1876 - val_f1: 0.0593 - val_loss: 1.4383
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 24ms/step - f1: 0.1306 - loss: 2.1794 - val_f1: 0.0593 - val_loss: 1.4232
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.1656 - loss: 2.1676 - val_f1: 0.0593 - val_loss: 1.4248
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 25ms/step - f1: 0.1426 - loss: 2.1737 - val_f1: 0.0593 - val_loss: 1.4155
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1537 - loss: 2.1533 - val_f1: 0.0593 - val_loss: 1.4223
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.1572 - loss: 1.9814 - val_f1: 0.0593 - val_loss: 1.4207
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1391 - loss: 2.1766 - val_f1: 0.0593 - val_loss: 1.4259
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1348 - loss: 2.1798 - val_f1: 0.0593 - val_loss: 1.4290
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1252 - loss: 2.1386 - val_f1: 0.0593 - val_loss: 1.4268
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1536 - loss: 2.1605 - val_f1: 0.0593 - val_loss: 1.3987
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1302 - loss: 2.1734 - val_f1: 0.0593 - val_loss: 1.4138
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1339 - loss: 2.1974 - val_f1: 0.0593 - val_loss: 1.4136
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1563 - loss: 2.1566 - val_f1: 0.0633 - val_loss: 1.4421
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.3259 - loss: 2.1276 - val_f1: 0.2431 - val_loss: 1.3220
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  9/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.2814 - loss: 2.1872
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 42ms/step - f1: 0.3739 - loss: 2.1702 - val_f1: 0.2013 - val_loss: 1.3884
Epoch 2/20
 93/100 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - f1: 0.4092 - loss: 2.1963
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4113 - loss: 2.1936 - val_f1: 0.5057 - val_loss: 1.1921
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4853 - loss: 2.0792 - val_f1: 0.4246 - val_loss: 1.1953
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4831 - loss: 2.0762 - val_f1: 0.4292 - val_loss: 1.2073
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5241 - loss: 1.9789 - val_f1: 0.5393 - val_loss: 1.0988
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5328 - loss: 1.9174 - val_f1: 0.5616 - val_loss: 1.0752
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5314 - loss: 1.9090 - val_f1: 0.4830 - val_loss: 1.1017
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5377 - loss: 1.9348 - val_f1: 0.5658 - val_loss: 0.9834
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5747 - loss: 1.8298 - val_f1: 0.4698 - val_loss: 1.1070
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5631 - loss: 1.8281 - val_f1: 0.5650 - val_loss: 1.0151
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5511 - loss: 1.8363 - val_f1: 0.5639 - val_loss: 1.0258
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5731 - loss: 1.8059 - val_f1: 0.5778 - val_loss: 1.0042
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5796 - loss: 1.8006 - val_f1: 0.5925 - val_loss: 0.9816
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6011 - loss: 1.7229 - val_f1: 0.6021 - val_loss: 0.9349
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.5831 - loss: 1.8056 - val_f1: 0.6064 - val_loss: 0.9839
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5960 - loss: 1.7342 - val_f1: 0.5805 - val_loss: 0.9315
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5876 - loss: 1.7141 - val_f1: 0.6464 - val_loss: 0.9398
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5922 - loss: 1.7211 - val_f1: 0.6060 - val_loss: 1.0099
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6221 - loss: 1.6837 - val_f1: 0.6308 - val_loss: 0.8511
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6043 - loss: 1.6725 - val_f1: 0.5838 - val_loss: 0.9000
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 34ms/step - f1: 0.1444 - loss: 2.3298 - val_f1: 0.1075 - val_loss: 1.3998
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 36ms/step - f1: 0.1990 - loss: 2.2712 - val_f1: 0.1417 - val_loss: 1.4163
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - f1: 0.1089 - loss: 2.2127
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.2026 - loss: 2.2380 - val_f1: 0.3963 - val_loss: 1.3368
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.3056 - loss: 2.2432 - val_f1: 0.1922 - val_loss: 1.4248
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.3404 - loss: 2.2198 - val_f1: 0.0414 - val_loss: 1.5263
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0595 - loss: 2.2300 - val_f1: 0.2035 - val_loss: 1.4232
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.3273 - loss: 2.2082 - val_f1: 0.1175 - val_loss: 1.4271
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.3289 - loss: 2.1829 - val_f1: 0.3860 - val_loss: 1.3127
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.4209 - loss: 1.9194 - val_f1: 0.3169 - val_loss: 1.3015
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4413 - loss: 2.0340 - val_f1: 0.3945 - val_loss: 1.2230
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4748 - loss: 1.9916 - val_f1: 0.4768 - val_loss: 1.1500
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5351 - loss: 2.0160 - val_f1: 0.5991 - val_loss: 1.1079
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4696 - loss: 2.0324 - val_f1: 0.5080 - val_loss: 1.2232
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4551 - loss: 1.9814 - val_f1: 0.3669 - val_loss: 1.1682
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5322 - loss: 1.8331 - val_f1: 0.4135 - val_loss: 1.1786
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 25ms/step - f1: 0.4634 - loss: 1.9596 - val_f1: 0.4457 - val_loss: 1.2463
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4908 - loss: 1.9181 - val_f1: 0.5124 - val_loss: 1.2141
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.4821 - loss: 1.9087 - val_f1: 0.4917 - val_loss: 1.1510
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5194 - loss: 1.8622 - val_f1: 0.6010 - val_loss: 1.0990
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5540 - loss: 1.7971 - val_f1: 0.4208 - val_loss: 1.1866
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  9/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.4708 - loss: 1.9923
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 28ms/step - f1: 0.5434 - loss: 1.7802 - val_f1: 0.4716 - val_loss: 1.1067
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 37ms/step - f1: 0.6218 - loss: 1.5949 - val_f1: 0.4001 - val_loss: 1.1682
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - f1: 0.6267 - loss: 1.5556
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.5844 - loss: 1.6390 - val_f1: 0.4384 - val_loss: 1.1717
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6142 - loss: 1.6452 - val_f1: 0.5212 - val_loss: 1.0684
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5958 - loss: 1.6351 - val_f1: 0.5255 - val_loss: 1.0087
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6461 - loss: 1.6937 - val_f1: 0.3829 - val_loss: 1.1533
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6107 - loss: 1.5896 - val_f1: 0.3013 - val_loss: 1.2838
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6073 - loss: 1.5890 - val_f1: 0.5220 - val_loss: 1.0720
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.6644 - loss: 1.4266 - val_f1: 0.4952 - val_loss: 1.1196
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6158 - loss: 1.6137 - val_f1: 0.5099 - val_loss: 1.0942
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6513 - loss: 1.5507 - val_f1: 0.5189 - val_loss: 1.0730
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5547 - loss: 1.6743 - val_f1: 0.5286 - val_loss: 0.9923
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.6505 - loss: 1.4904 - val_f1: 0.5430 - val_loss: 0.9870
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6558 - loss: 1.4608 - val_f1: 0.5473 - val_loss: 0.9949
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.6523 - loss: 1.6201 - val_f1: 0.5246 - val_loss: 0.9741
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6595 - loss: 1.4915 - val_f1: 0.5455 - val_loss: 0.9761
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6555 - loss: 1.5447 - val_f1: 0.2551 - val_loss: 1.6421
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.2153 - loss: 2.3201 - val_f1: 0.2200 - val_loss: 1.6095
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5274 - loss: 1.7568 - val_f1: 0.5703 - val_loss: 0.9695
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6818 - loss: 1.4239 - val_f1: 0.5562 - val_loss: 0.9479
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  9/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.6258 - loss: 1.7155
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 42ms/step - f1: 0.6071 - loss: 1.6839 - val_f1: 0.6628 - val_loss: 0.7372
Epoch 2/20
 91/100 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - f1: 0.6004 - loss: 1.6726
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6010 - loss: 1.6688 - val_f1: 0.7156 - val_loss: 0.7433
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6133 - loss: 1.5899 - val_f1: 0.6781 - val_loss: 0.7840
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6272 - loss: 1.6042 - val_f1: 0.6909 - val_loss: 0.7483
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6346 - loss: 1.6172 - val_f1: 0.6554 - val_loss: 0.7610
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6283 - loss: 1.5567 - val_f1: 0.6410 - val_loss: 0.7620
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6216 - loss: 1.5783 - val_f1: 0.6597 - val_loss: 0.7660
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6293 - loss: 1.6110 - val_f1: 0.6762 - val_loss: 0.7501
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.6325 - loss: 1.5936 - val_f1: 0.7052 - val_loss: 0.7591
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6497 - loss: 1.5643 - val_f1: 0.6455 - val_loss: 0.9674
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.6266 - loss: 1.5653 - val_f1: 0.7336 - val_loss: 0.7393
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6190 - loss: 1.5972 - val_f1: 0.6932 - val_loss: 0.7456
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6598 - loss: 1.4801 - val_f1: 0.6977 - val_loss: 0.7202
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6699 - loss: 1.5248 - val_f1: 0.7260 - val_loss: 0.7190
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6691 - loss: 1.4966 - val_f1: 0.6919 - val_loss: 0.7402
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6530 - loss: 1.4893 - val_f1: 0.7105 - val_loss: 0.7764
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.6444 - loss: 1.5519 - val_f1: 0.7069 - val_loss: 0.7950
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6612 - loss: 1.5550 - val_f1: 0.6940 - val_loss: 0.7305
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6465 - loss: 1.5340 - val_f1: 0.7179 - val_loss: 0.7462
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6493 - loss: 1.5542 - val_f1: 0.7241 - val_loss: 0.7380
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 7s 51ms/step - f1: 0.1597 - loss: 2.3179 - val_f1: 0.0094 - val_loss: 1.4224
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1176 - loss: 2.3173 - val_f1: 0.0829 - val_loss: 1.3928
Epoch 3/20
  3/100 ━━━━━━━━━━━━━━━━━━━━ 4s 44ms/step - f1: 0.2169 - loss: 2.2489
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.2253 - loss: 2.2310 - val_f1: 0.4132 - val_loss: 1.3411
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.3492 - loss: 2.2162 - val_f1: 0.2921 - val_loss: 1.2542
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4313 - loss: 2.0875 - val_f1: 0.5520 - val_loss: 1.1982
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.3713 - loss: 2.1180 - val_f1: 0.4791 - val_loss: 1.2300
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4503 - loss: 2.0363 - val_f1: 0.5640 - val_loss: 1.1868
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5087 - loss: 1.9860 - val_f1: 0.6193 - val_loss: 1.0113
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6219 - loss: 1.8992 - val_f1: 0.5545 - val_loss: 1.1751
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5350 - loss: 1.9466 - val_f1: 0.4141 - val_loss: 1.2897
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5023 - loss: 2.0035 - val_f1: 0.4831 - val_loss: 1.3263
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.5558 - loss: 1.8615 - val_f1: 0.5384 - val_loss: 1.0374
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5432 - loss: 1.8989 - val_f1: 0.5924 - val_loss: 1.0683
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5820 - loss: 1.8004 - val_f1: 0.6494 - val_loss: 0.9232
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6039 - loss: 1.6867 - val_f1: 0.6495 - val_loss: 0.9329
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5702 - loss: 1.7954 - val_f1: 0.5688 - val_loss: 1.0468
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 24ms/step - f1: 0.6103 - loss: 1.7212 - val_f1: 0.6078 - val_loss: 0.9745
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6574 - loss: 1.6497 - val_f1: 0.6642 - val_loss: 0.8705
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5894 - loss: 1.8147 - val_f1: 0.6705 - val_loss: 0.8662
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6042 - loss: 1.7140 - val_f1: 0.6045 - val_loss: 0.9582
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - f1: 0.5810 - loss: 1.9693
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 41ms/step - f1: 0.6177 - loss: 1.6696 - val_f1: 0.5585 - val_loss: 0.9972
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6189 - loss: 1.6317 - val_f1: 0.5943 - val_loss: 0.9497
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - f1: 0.7314 - loss: 1.2067
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6842 - loss: 1.4704 - val_f1: 0.5835 - val_loss: 0.9394
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6503 - loss: 1.5542 - val_f1: 0.5691 - val_loss: 0.9718
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6358 - loss: 1.6002 - val_f1: 0.5157 - val_loss: 1.0694
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6249 - loss: 1.6179 - val_f1: 0.5029 - val_loss: 1.0845
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6718 - loss: 1.5023 - val_f1: 0.6275 - val_loss: 0.8781
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6326 - loss: 1.6375 - val_f1: 0.5569 - val_loss: 0.9371
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5840 - loss: 1.7913 - val_f1: 0.5049 - val_loss: 1.1209
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6442 - loss: 1.5347 - val_f1: 0.5139 - val_loss: 1.1801
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6509 - loss: 1.5484 - val_f1: 0.5519 - val_loss: 0.9956
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7748 - loss: 1.0626 - val_f1: 0.5541 - val_loss: 1.0032
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6391 - loss: 1.5666 - val_f1: 0.5604 - val_loss: 0.9700
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6664 - loss: 1.4913 - val_f1: 0.5969 - val_loss: 1.0847
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7379 - loss: 1.4081 - val_f1: 0.5787 - val_loss: 1.0371
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6838 - loss: 1.4520 - val_f1: 0.3739 - val_loss: 1.1792
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5837 - loss: 1.7115 - val_f1: 0.4611 - val_loss: 1.1798
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.5627 - loss: 1.7017 - val_f1: 0.4812 - val_loss: 1.0535
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6353 - loss: 1.5946 - val_f1: 0.4513 - val_loss: 1.1821
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6250 - loss: 1.6034 - val_f1: 0.5513 - val_loss: 0.9422
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.5605 - loss: 1.6801
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 43ms/step - f1: 0.5898 - loss: 1.7295 - val_f1: 0.7259 - val_loss: 0.7839
Epoch 2/20
 94/100 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - f1: 0.6213 - loss: 1.6436
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.6208 - loss: 1.6454 - val_f1: 0.6959 - val_loss: 0.8066
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5962 - loss: 1.7156 - val_f1: 0.6710 - val_loss: 0.8597
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.6284 - loss: 1.5958 - val_f1: 0.7255 - val_loss: 0.7753
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6262 - loss: 1.6052 - val_f1: 0.6513 - val_loss: 1.0252
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.6154 - loss: 1.6294 - val_f1: 0.6130 - val_loss: 0.8730
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6322 - loss: 1.6092 - val_f1: 0.6959 - val_loss: 0.7964
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6404 - loss: 1.5950 - val_f1: 0.6988 - val_loss: 0.8659
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6399 - loss: 1.5421 - val_f1: 0.6675 - val_loss: 0.8553
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6544 - loss: 1.5948 - val_f1: 0.6908 - val_loss: 0.8716
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6574 - loss: 1.5340 - val_f1: 0.6825 - val_loss: 0.7970
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.6614 - loss: 1.5744 - val_f1: 0.6717 - val_loss: 0.9684
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6486 - loss: 1.5778 - val_f1: 0.6881 - val_loss: 0.7579
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.6727 - loss: 1.5172 - val_f1: 0.7150 - val_loss: 0.7798
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6695 - loss: 1.4969 - val_f1: 0.7127 - val_loss: 0.7636
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.6589 - loss: 1.5494 - val_f1: 0.6965 - val_loss: 0.7449
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6892 - loss: 1.4288 - val_f1: 0.6709 - val_loss: 0.8113
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.6828 - loss: 1.4522 - val_f1: 0.6806 - val_loss: 0.8055
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6894 - loss: 1.4706 - val_f1: 0.6969 - val_loss: 0.8021
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.6762 - loss: 1.4873 - val_f1: 0.6923 - val_loss: 0.8143
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 5s 32ms/step - f1: 0.1721 - loss: 3.1246 - val_f1: 0.0093 - val_loss: 2.1396
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 35ms/step - f1: 0.1570 - loss: 2.9839 - val_f1: 0.2989 - val_loss: 1.9936
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - f1: 0.2516 - loss: 2.8421
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.3115 - loss: 2.9715 - val_f1: 0.1522 - val_loss: 1.9957
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.3254 - loss: 2.7966 - val_f1: 0.3202 - val_loss: 1.8239
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.3306 - loss: 2.7418 - val_f1: 0.3746 - val_loss: 1.6753
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.4127 - loss: 2.5697 - val_f1: 0.0903 - val_loss: 1.9588
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.3334 - loss: 2.6284 - val_f1: 0.3245 - val_loss: 1.6465
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.2791 - loss: 2.5797 - val_f1: 0.4150 - val_loss: 1.5965
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.3522 - loss: 2.4089 - val_f1: 0.3854 - val_loss: 1.5954
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.3545 - loss: 2.4637 - val_f1: 0.1075 - val_loss: 1.6724
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1302 - loss: 2.5245 - val_f1: 0.1058 - val_loss: 1.6506
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1329 - loss: 2.6439 - val_f1: 0.0323 - val_loss: 1.6463
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.3418 - loss: 2.3637 - val_f1: 0.2851 - val_loss: 1.5296
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.2822 - loss: 2.4235 - val_f1: 0.0306 - val_loss: 1.5892
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.2013 - loss: 2.4730 - val_f1: 0.1075 - val_loss: 1.5941
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1339 - loss: 2.4237 - val_f1: 0.1075 - val_loss: 1.5358
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.2186 - loss: 2.3651 - val_f1: 0.0094 - val_loss: 1.8890
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0605 - loss: 2.5671 - val_f1: 0.0420 - val_loss: 1.6408
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1426 - loss: 2.4039 - val_f1: 0.1075 - val_loss: 1.5201
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1747 - loss: 2.3631 - val_f1: 0.3649 - val_loss: 1.2447
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  9/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.3402 - loss: 2.1187
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 39ms/step - f1: 0.2979 - loss: 2.1924 - val_f1: 0.0593 - val_loss: 1.4904
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.2113 - loss: 2.2677 - val_f1: 0.2537 - val_loss: 1.3735
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - f1: 0.4538 - loss: 2.1091
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.3926 - loss: 2.2086 - val_f1: 0.1808 - val_loss: 1.4437
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.3688 - loss: 2.1420 - val_f1: 0.2859 - val_loss: 1.3365
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.3951 - loss: 2.0626 - val_f1: 0.0593 - val_loss: 1.4790
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0815 - loss: 2.1369 - val_f1: 0.0593 - val_loss: 1.4781
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1399 - loss: 2.2284 - val_f1: 0.0593 - val_loss: 1.4559
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.2313 - loss: 2.1625 - val_f1: 0.1558 - val_loss: 1.4637
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.3852 - loss: 2.3792 - val_f1: 0.1121 - val_loss: 1.6218
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.2365 - loss: 2.1797 - val_f1: 0.2396 - val_loss: 1.4606
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.3227 - loss: 2.1898 - val_f1: 0.0908 - val_loss: 1.4454
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1972 - loss: 2.1873 - val_f1: 0.1738 - val_loss: 1.4049
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.3820 - loss: 2.0916 - val_f1: 0.2735 - val_loss: 1.3291
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4078 - loss: 2.0640 - val_f1: 0.3315 - val_loss: 1.2892
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.3984 - loss: 2.1901 - val_f1: 0.2314 - val_loss: 1.3658
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.3968 - loss: 2.0998 - val_f1: 0.1674 - val_loss: 1.4548
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.3948 - loss: 2.0684 - val_f1: 0.2163 - val_loss: 1.3621
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.3554 - loss: 2.0816 - val_f1: 0.3635 - val_loss: 1.2501
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.3771 - loss: 2.1228 - val_f1: 0.2394 - val_loss: 1.3637
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.3892 - loss: 2.0966 - val_f1: 0.0593 - val_loss: 1.6315
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.1404 - loss: 2.2620
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 42ms/step - f1: 0.1377 - loss: 2.3247 - val_f1: 0.1683 - val_loss: 1.4178
Epoch 2/20
 91/100 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - f1: 0.2412 - loss: 2.2795
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.2352 - loss: 2.2791 - val_f1: 0.0276 - val_loss: 1.4243
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1377 - loss: 2.2790 - val_f1: 0.0276 - val_loss: 1.4355
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1013 - loss: 2.2702 - val_f1: 0.0358 - val_loss: 1.4149
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.2710 - loss: 2.2445 - val_f1: 0.0382 - val_loss: 1.4923
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.3160 - loss: 2.1848 - val_f1: 0.0276 - val_loss: 1.5121
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1142 - loss: 2.2914 - val_f1: 0.0276 - val_loss: 1.4401
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.1444 - loss: 2.2345 - val_f1: 0.0305 - val_loss: 1.4645
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.1154 - loss: 2.3077 - val_f1: 0.3251 - val_loss: 1.2676
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.3022 - loss: 2.2277 - val_f1: 0.0276 - val_loss: 1.4288
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1047 - loss: 2.2810 - val_f1: 0.0276 - val_loss: 1.4215
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.1053 - loss: 2.2869 - val_f1: 0.0276 - val_loss: 1.4283
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1174 - loss: 2.2785 - val_f1: 0.0276 - val_loss: 1.4161
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.0913 - loss: 2.2681 - val_f1: 0.0276 - val_loss: 1.3966
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1037 - loss: 2.2710 - val_f1: 0.0276 - val_loss: 1.4051
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1562 - loss: 2.2424 - val_f1: 0.0354 - val_loss: 1.4278
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.2772 - loss: 2.2497 - val_f1: 0.0276 - val_loss: 1.4621
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.1119 - loss: 2.2491 - val_f1: 0.0276 - val_loss: 1.4086
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1137 - loss: 2.2390 - val_f1: 0.0276 - val_loss: 1.4052
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.1111 - loss: 2.2602 - val_f1: 0.3261 - val_loss: 1.3470
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 33ms/step - f1: 0.1839 - loss: 3.0978 - val_f1: 0.1075 - val_loss: 2.0212
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 20ms/step - f1: 0.0966 - loss: 2.8133 - val_f1: 0.0094 - val_loss: 1.8868
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - f1: 0.0949 - loss: 2.6988
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0845 - loss: 2.6431 - val_f1: 0.0094 - val_loss: 1.8615
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1078 - loss: 2.6505 - val_f1: 0.0094 - val_loss: 1.7369
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.0773 - loss: 2.5610 - val_f1: 0.3163 - val_loss: 1.5487
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.3450 - loss: 2.3865 - val_f1: 0.2268 - val_loss: 1.5640
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.2631 - loss: 2.4689 - val_f1: 0.1075 - val_loss: 1.5199
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1237 - loss: 2.3963 - val_f1: 0.1075 - val_loss: 1.5080
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0819 - loss: 2.3393 - val_f1: 0.1075 - val_loss: 1.5084
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1362 - loss: 2.4171 - val_f1: 0.0094 - val_loss: 1.5098
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.0709 - loss: 2.3734 - val_f1: 0.1075 - val_loss: 1.4688
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0516 - loss: 2.1442 - val_f1: 0.1075 - val_loss: 1.4611
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1011 - loss: 2.3446 - val_f1: 0.1075 - val_loss: 1.4238
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1204 - loss: 2.3207 - val_f1: 0.1075 - val_loss: 1.4045
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1775 - loss: 2.2041 - val_f1: 0.1075 - val_loss: 1.4050
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1127 - loss: 2.2965 - val_f1: 0.1075 - val_loss: 1.4537
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1204 - loss: 2.2985 - val_f1: 0.1075 - val_loss: 1.4395
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.1171 - loss: 2.2790 - val_f1: 0.1075 - val_loss: 1.4407
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1348 - loss: 2.3081 - val_f1: 0.1075 - val_loss: 1.4237
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1195 - loss: 2.2911 - val_f1: 0.0094 - val_loss: 1.4528
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  9/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.1069 - loss: 2.3185
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 39ms/step - f1: 0.1495 - loss: 2.1973 - val_f1: 0.0593 - val_loss: 1.4165
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1272 - loss: 2.1944 - val_f1: 0.0593 - val_loss: 1.4181
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - f1: 0.2002 - loss: 2.0431
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1462 - loss: 2.0709 - val_f1: 0.0593 - val_loss: 1.4184
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1306 - loss: 2.1934 - val_f1: 0.0593 - val_loss: 1.4161
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1429 - loss: 2.1255 - val_f1: 0.0593 - val_loss: 1.4090
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1254 - loss: 2.0468 - val_f1: 0.0593 - val_loss: 1.4095
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1334 - loss: 2.1552 - val_f1: 0.0593 - val_loss: 1.4033
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1365 - loss: 2.1384 - val_f1: 0.0593 - val_loss: 1.4200
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1251 - loss: 2.2120 - val_f1: 0.0593 - val_loss: 1.4232
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 25ms/step - f1: 0.1461 - loss: 2.1869 - val_f1: 0.0593 - val_loss: 1.3954
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.1320 - loss: 2.1625 - val_f1: 0.0593 - val_loss: 1.4279
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1901 - loss: 2.4040 - val_f1: 0.0593 - val_loss: 1.4301
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1353 - loss: 2.1676 - val_f1: 0.0593 - val_loss: 1.4230
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1404 - loss: 2.1880 - val_f1: 0.0593 - val_loss: 1.4027
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1064 - loss: 2.2025 - val_f1: 0.0593 - val_loss: 1.4010
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 24ms/step - f1: 0.1466 - loss: 2.1602 - val_f1: 0.0593 - val_loss: 1.4231
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1324 - loss: 2.1688 - val_f1: 0.0593 - val_loss: 1.4154
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0981 - loss: 2.0293 - val_f1: 0.0593 - val_loss: 1.4114
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1334 - loss: 2.1787 - val_f1: 0.0593 - val_loss: 1.4105
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1452 - loss: 2.1991 - val_f1: 0.0593 - val_loss: 1.4138
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  4/100 ━━━━━━━━━━━━━━━━━━━━ 1s 18ms/step - f1: 0.1373 - loss: 2.4155
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 43ms/step - f1: 0.1302 - loss: 2.3014 - val_f1: 0.0276 - val_loss: 1.3847
Epoch 2/20
 94/100 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - f1: 0.1075 - loss: 2.2754
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1072 - loss: 2.2742 - val_f1: 0.0276 - val_loss: 1.3977
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1051 - loss: 2.2828 - val_f1: 0.0276 - val_loss: 1.4092
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1091 - loss: 2.2284 - val_f1: 0.0276 - val_loss: 1.3914
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1096 - loss: 2.2468 - val_f1: 0.0276 - val_loss: 1.4048
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1420 - loss: 2.2686 - val_f1: 0.0276 - val_loss: 1.4061
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.0975 - loss: 2.2112 - val_f1: 0.0276 - val_loss: 1.3902
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1160 - loss: 2.2928 - val_f1: 0.0276 - val_loss: 1.3902
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1179 - loss: 2.2871 - val_f1: 0.1683 - val_loss: 1.3752
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1436 - loss: 2.2376 - val_f1: 0.0276 - val_loss: 1.3949
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.0957 - loss: 2.2409 - val_f1: 0.0276 - val_loss: 1.3993
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1107 - loss: 2.2542 - val_f1: 0.0276 - val_loss: 1.4287
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1064 - loss: 2.2265 - val_f1: 0.0276 - val_loss: 1.4116
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1049 - loss: 2.2392 - val_f1: 0.0276 - val_loss: 1.4057
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1066 - loss: 2.2438 - val_f1: 0.0276 - val_loss: 1.3893
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1023 - loss: 2.2601 - val_f1: 0.0276 - val_loss: 1.3918
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1661 - loss: 2.2192 - val_f1: 0.0276 - val_loss: 1.4315
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1305 - loss: 2.2401 - val_f1: 0.0276 - val_loss: 1.3855
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.1079 - loss: 2.2767 - val_f1: 0.0276 - val_loss: 1.3867
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.0989 - loss: 2.2424 - val_f1: 0.0276 - val_loss: 1.3962
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 34ms/step - f1: 0.1482 - loss: 3.1515 - val_f1: 0.1012 - val_loss: 2.1103
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 38ms/step - f1: 0.2613 - loss: 2.9492 - val_f1: 0.2414 - val_loss: 1.9593
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - f1: 0.2553 - loss: 2.9788
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.2818 - loss: 2.9704 - val_f1: 0.2414 - val_loss: 1.9826
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1506 - loss: 2.8702 - val_f1: 0.1066 - val_loss: 1.8624
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.2559 - loss: 2.7213 - val_f1: 0.3524 - val_loss: 1.7054
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.5419 - loss: 2.4672 - val_f1: 0.2896 - val_loss: 1.7224
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.3756 - loss: 2.6186 - val_f1: 0.4423 - val_loss: 1.6082
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4319 - loss: 2.4359 - val_f1: 0.4721 - val_loss: 1.5082
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.4658 - loss: 2.3696 - val_f1: 0.4330 - val_loss: 1.6380
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4365 - loss: 2.3541 - val_f1: 0.4919 - val_loss: 1.4472
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4427 - loss: 2.3294 - val_f1: 0.5054 - val_loss: 1.4496
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5173 - loss: 2.1986 - val_f1: 0.5572 - val_loss: 1.4001
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4440 - loss: 2.2999 - val_f1: 0.3882 - val_loss: 1.5764
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4671 - loss: 2.2591 - val_f1: 0.4901 - val_loss: 1.3782
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.5110 - loss: 2.1282 - val_f1: 0.5895 - val_loss: 1.3142
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5192 - loss: 2.1323 - val_f1: 0.3609 - val_loss: 1.4437
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4870 - loss: 2.1971 - val_f1: 0.4047 - val_loss: 1.5038
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5759 - loss: 2.0094 - val_f1: 0.5073 - val_loss: 1.2234
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5425 - loss: 2.0504 - val_f1: 0.5385 - val_loss: 1.3458
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5391 - loss: 2.0932 - val_f1: 0.6334 - val_loss: 1.1425
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - f1: 0.6211 - loss: 1.8812
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 26ms/step - f1: 0.5732 - loss: 1.9715 - val_f1: 0.5211 - val_loss: 1.2370
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 35ms/step - f1: 0.5728 - loss: 1.9479 - val_f1: 0.3687 - val_loss: 1.4888
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - f1: 0.4671 - loss: 1.7830
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5885 - loss: 1.7833 - val_f1: 0.4865 - val_loss: 1.2505
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5784 - loss: 1.9374 - val_f1: 0.4628 - val_loss: 1.1968
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5917 - loss: 1.8828 - val_f1: 0.5052 - val_loss: 1.2019
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5199 - loss: 2.0513 - val_f1: 0.4544 - val_loss: 1.3524
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5954 - loss: 1.8414 - val_f1: 0.4936 - val_loss: 1.1660
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5997 - loss: 1.8359 - val_f1: 0.3850 - val_loss: 1.3522
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.5879 - loss: 1.8021 - val_f1: 0.5106 - val_loss: 1.1717
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6301 - loss: 1.7408 - val_f1: 0.3614 - val_loss: 1.5539
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.5942 - loss: 1.8427 - val_f1: 0.5397 - val_loss: 1.1815
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7088 - loss: 1.6044 - val_f1: 0.5483 - val_loss: 1.1892
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5936 - loss: 1.8449 - val_f1: 0.4190 - val_loss: 1.3459
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5699 - loss: 1.9317 - val_f1: 0.5513 - val_loss: 1.1206
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5730 - loss: 1.9186 - val_f1: 0.5398 - val_loss: 1.1262
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6022 - loss: 1.8288 - val_f1: 0.4982 - val_loss: 1.1485
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6073 - loss: 1.8347 - val_f1: 0.5380 - val_loss: 1.1238
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.5901 - loss: 1.7060 - val_f1: 0.3067 - val_loss: 1.6329
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6097 - loss: 1.7892 - val_f1: 0.5435 - val_loss: 1.1275
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6049 - loss: 1.7777 - val_f1: 0.4529 - val_loss: 1.2487
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - f1: 0.4617 - loss: 2.1900
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 42ms/step - f1: 0.5331 - loss: 2.0277 - val_f1: 0.6718 - val_loss: 0.9291
Epoch 2/20
 91/100 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - f1: 0.5509 - loss: 1.9482
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5511 - loss: 1.9489 - val_f1: 0.6610 - val_loss: 0.9667
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5574 - loss: 1.9246 - val_f1: 0.6669 - val_loss: 0.9861
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5727 - loss: 1.8545 - val_f1: 0.6599 - val_loss: 0.9885
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5719 - loss: 1.8945 - val_f1: 0.6717 - val_loss: 1.0516
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.4948 - loss: 2.0546 - val_f1: 0.6337 - val_loss: 1.0930
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5516 - loss: 1.9314 - val_f1: 0.6595 - val_loss: 1.0497
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5587 - loss: 1.9255 - val_f1: 0.6241 - val_loss: 1.0300
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5297 - loss: 1.9770 - val_f1: 0.6564 - val_loss: 1.0418
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5720 - loss: 1.8729 - val_f1: 0.6191 - val_loss: 1.0566
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6102 - loss: 1.8235 - val_f1: 0.5276 - val_loss: 1.3577
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5344 - loss: 1.9836 - val_f1: 0.4201 - val_loss: 1.5184
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5509 - loss: 1.9175 - val_f1: 0.6499 - val_loss: 1.0291
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5460 - loss: 1.9397 - val_f1: 0.6554 - val_loss: 1.0293
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5872 - loss: 1.8619 - val_f1: 0.5955 - val_loss: 1.1127
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5601 - loss: 1.8732 - val_f1: 0.6561 - val_loss: 1.0484
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5842 - loss: 1.8532 - val_f1: 0.4870 - val_loss: 1.3830
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5703 - loss: 1.9016 - val_f1: 0.5365 - val_loss: 1.0365
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.5682 - loss: 1.8944 - val_f1: 0.6434 - val_loss: 1.0693
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5999 - loss: 1.8336 - val_f1: 0.6136 - val_loss: 1.0213
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 34ms/step - f1: 0.1470 - loss: 3.1249 - val_f1: 0.0094 - val_loss: 2.0368
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 34ms/step - f1: 0.1327 - loss: 2.8866 - val_f1: 0.0094 - val_loss: 1.8331
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - f1: 0.0382 - loss: 2.4731
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0382 - loss: 2.5633 - val_f1: 0.0094 - val_loss: 1.8264
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.0832 - loss: 2.6641 - val_f1: 0.1075 - val_loss: 1.7005
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1157 - loss: 2.5379 - val_f1: 0.1075 - val_loss: 1.5952
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1939 - loss: 2.5479 - val_f1: 0.1075 - val_loss: 1.5937
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1340 - loss: 2.4199 - val_f1: 0.0094 - val_loss: 1.5498
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1140 - loss: 2.3976 - val_f1: 0.1075 - val_loss: 1.4983
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.1159 - loss: 2.3415 - val_f1: 0.1075 - val_loss: 1.5026
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1879 - loss: 2.3351 - val_f1: 0.3966 - val_loss: 1.3815
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.2676 - loss: 2.3582 - val_f1: 0.1075 - val_loss: 1.4579
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1154 - loss: 2.4954 - val_f1: 0.1075 - val_loss: 1.4586
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1200 - loss: 2.3302 - val_f1: 0.1075 - val_loss: 1.4547
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1184 - loss: 2.3392 - val_f1: 0.0094 - val_loss: 1.4404
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0176 - loss: 2.2250 - val_f1: 0.0094 - val_loss: 1.4339
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.0596 - loss: 2.3089 - val_f1: 0.0094 - val_loss: 1.4630
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1319 - loss: 2.3056 - val_f1: 0.1075 - val_loss: 1.4436
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1661 - loss: 2.3777 - val_f1: 0.1075 - val_loss: 1.4471
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1322 - loss: 2.2957 - val_f1: 0.1075 - val_loss: 1.4291
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1140 - loss: 2.2773 - val_f1: 0.1075 - val_loss: 1.4567
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.1694 - loss: 2.1788
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 25ms/step - f1: 0.1334 - loss: 2.2027 - val_f1: 0.0593 - val_loss: 1.4251
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 34ms/step - f1: 0.1529 - loss: 2.2062 - val_f1: 0.0593 - val_loss: 1.4126
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - f1: 0.1667 - loss: 2.0833
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.1774 - loss: 2.2654 - val_f1: 0.0593 - val_loss: 1.4128
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1394 - loss: 2.1883 - val_f1: 0.0593 - val_loss: 1.4133
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1507 - loss: 2.1761 - val_f1: 0.0593 - val_loss: 1.4060
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1266 - loss: 2.0321 - val_f1: 0.0593 - val_loss: 1.4063
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1370 - loss: 2.1794 - val_f1: 0.0593 - val_loss: 1.4282
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1512 - loss: 2.1192 - val_f1: 0.0593 - val_loss: 1.4269
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.1883 - loss: 2.4716 - val_f1: 0.0593 - val_loss: 1.4289
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1355 - loss: 2.2104 - val_f1: 0.0593 - val_loss: 1.4316
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1275 - loss: 2.2035 - val_f1: 0.0593 - val_loss: 1.4149
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.1564 - loss: 2.2810 - val_f1: 0.0593 - val_loss: 1.4176
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1499 - loss: 2.2250 - val_f1: 0.0593 - val_loss: 1.4316
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1205 - loss: 2.1803 - val_f1: 0.0593 - val_loss: 1.3987
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.1438 - loss: 2.1481 - val_f1: 0.0593 - val_loss: 1.3987
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1500 - loss: 2.1827 - val_f1: 0.0593 - val_loss: 1.4152
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1371 - loss: 2.1745 - val_f1: 0.0593 - val_loss: 1.4126
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.0886 - loss: 2.0578 - val_f1: 0.0593 - val_loss: 1.4103
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1311 - loss: 2.1895 - val_f1: 0.0593 - val_loss: 1.4092
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1537 - loss: 2.1723 - val_f1: 0.0593 - val_loss: 1.4129
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.0689 - loss: 2.0575
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 42ms/step - f1: 0.1240 - loss: 2.2410 - val_f1: 0.0276 - val_loss: 1.4277
Epoch 2/20
 94/100 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - f1: 0.0978 - loss: 2.2527
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.0978 - loss: 2.2527 - val_f1: 0.0276 - val_loss: 1.3946
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1091 - loss: 2.2462 - val_f1: 0.0276 - val_loss: 1.3848
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1062 - loss: 2.2035 - val_f1: 0.0276 - val_loss: 1.3960
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1061 - loss: 2.2464 - val_f1: 0.0276 - val_loss: 1.3884
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1238 - loss: 2.2335 - val_f1: 0.1683 - val_loss: 1.3777
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1242 - loss: 2.2328 - val_f1: 0.0276 - val_loss: 1.3961
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.0992 - loss: 2.2311 - val_f1: 0.0276 - val_loss: 1.4079
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1144 - loss: 2.2463 - val_f1: 0.0276 - val_loss: 1.3930
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.1060 - loss: 2.2485 - val_f1: 0.0276 - val_loss: 1.4167
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.1118 - loss: 2.2701 - val_f1: 0.0276 - val_loss: 1.4027
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.1375 - loss: 2.2670 - val_f1: 0.0276 - val_loss: 1.4058
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1139 - loss: 2.2692 - val_f1: 0.0276 - val_loss: 1.4189
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.1011 - loss: 2.2634 - val_f1: 0.0276 - val_loss: 1.3941
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1206 - loss: 2.2437 - val_f1: 0.0276 - val_loss: 1.4131
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1294 - loss: 2.2313 - val_f1: 0.0276 - val_loss: 1.4020
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.1055 - loss: 2.2645 - val_f1: 0.0276 - val_loss: 1.3964
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1155 - loss: 2.2362 - val_f1: 0.2245 - val_loss: 1.3609
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1520 - loss: 2.2530 - val_f1: 0.0276 - val_loss: 1.4026
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.1138 - loss: 2.2801 - val_f1: 0.0276 - val_loss: 1.4093