- For train set, picked 27 patients out of 34 patients with cancerous cells
- For train set, picked 21 patients out of 26 patients with non cancerous cells
- Therefore, there is a ratio of cancerous to total patients in train set of 0.5625 
- Therefore, there is a ratio of cancerous to total patients in test set of 0.5833333333333334 
- For fold set 0, picked 27 patients out of 27 train set patients with cancerous cells
- For fold set 0, picked 21 patients out of 21 train set patients with non cancerous cells
- Therefore, there is a ratio of cancerous to total patient in fold set 0 of 0.5625
- For fold set 1, picked 18 patients out of 27 train set patients with cancerous cells
- For fold set 1, picked 14 patients out of 21 train set patients with non cancerous cells
- Therefore, there is a ratio of cancerous to total patient in fold set 1 of 0.5625
- For fold set 2, picked 9 patients out of 27 train set patients with cancerous cells
- For fold set 2, picked 7 patients out of 21 train set patients with non cancerous cells
- Therefore, there is a ratio of cancerous to total patient in fold set 2 of 0.5625
Adding isCancerous: patient:6 to fold 0
Adding isCancerous: patient:7 to fold 1
Adding isCancerous: patient:8 to fold 2
Adding isCancerous: patient:9 to fold 0
Adding isCancerous: patient:10 to fold 1
Adding isCancerous: patient:13 to fold 0
Adding isCancerous: patient:14 to fold 2
Adding isCancerous: patient:17 to fold 0
Adding isCancerous: patient:19 to fold 2
Adding isCancerous: patient:20 to fold 2
Adding isCancerous: patient:21 to fold 1
Adding isCancerous: patient:22 to fold 0
Adding isCancerous: patient:30 to fold 0
Adding isCancerous: patient:32 to fold 2
Adding isCancerous: patient:38 to fold 1
Adding isCancerous: patient:40 to fold 0
Adding isCancerous: patient:41 to fold 2
Adding isCancerous: patient:42 to fold 0
Adding isCancerous: patient:43 to fold 1
Adding isCancerous: patient:46 to fold 1
Adding isCancerous: patient:47 to fold 1
Adding isCancerous: patient:49 to fold 2
Adding isCancerous: patient:52 to fold 1
Adding isCancerous: patient:53 to fold 2
Adding isCancerous: patient:54 to fold 1
Adding isCancerous: patient:55 to fold 2
Adding isCancerous: patient:60 to fold 0
Adding NonCancerous: patient2 to fold 2
Adding NonCancerous: patient3 to fold 0
Adding NonCancerous: patient4 to fold 2
Adding NonCancerous: patient12 to fold 1
Adding NonCancerous: patient15 to fold 0
Adding NonCancerous: patient16 to fold 2
Adding NonCancerous: patient23 to fold 1
Adding NonCancerous: patient25 to fold 1
Adding NonCancerous: patient26 to fold 2
Adding NonCancerous: patient27 to fold 1
Adding NonCancerous: patient28 to fold 1
Adding NonCancerous: patient29 to fold 2
Adding NonCancerous: patient34 to fold 2
Adding NonCancerous: patient37 to fold 0
Adding NonCancerous: patient39 to fold 2
Adding NonCancerous: patient44 to fold 0
Adding NonCancerous: patient45 to fold 1
Adding NonCancerous: patient56 to fold 0
Adding NonCancerous: patient57 to fold 0
Adding NonCancerous: patient58 to fold 0
Adding NonCancerous: patient59 to fold 1
- There is 16 patients in the fold set 0. The count for each cell type is:
cellType
2    1079
1     680
0     669
3     185
Name: count, dtype: int64
- There is 16 patients in the fold set 1. The count for each cell type is:
cellType
2    974
0    651
3    491
1    489
Name: count, dtype: int64
- There is 16 patients in the fold set 2. The count for each cell type is:
cellType
2    1130
1     957
3     412
0     356
Name: count, dtype: int64
- There is 39 patients in the train set.
- There is 12 patients in the test set. The count for each cell type is:
cellType
2    896
1    417
3    298
0    212
Name: count, dtype: int64
- Therefore, ratio of train to total is: 0.815784155214228 versus the ratio of test to total: 0.18421584478577202
- Therefore, ratio of fold set 0 to train is: 0.32367149758454106, and the ratio of fold set 0 to total is: 0.26404607922392886
- Therefore, ratio of fold set 1 to train is: 0.32268054007184443, and the ratio of fold set 1 to total is: 0.2632376717865804
- Therefore, ratio of fold set 2 to train is: 0.3536479623436145, and the ratio of fold set 2 to total is: 0.2885004042037187
- The value counts for isCancerous for fold set 0 is:
isCancerous
0    1534
1    1079
Name: count, dtype: int64
- The value counts for isCancerous for fold set 1 is:
isCancerous
0    1631
1     974
Name: count, dtype: int64
- The value counts for isCancerous for fold set 2 is:
isCancerous
0    1725
1    1130
Name: count, dtype: int64
- The value counts for isCancerous for train set is:
3183
- The value counts for isCancerous for test set is:
isCancerous
0    927
1    896
Name: count, dtype: int64
- The value counts for isCancerous for whole data set is:
isCancerous
0    5817
1    4079
Name: count, dtype: int64
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 7s 41ms/step - f1: 0.5338 - loss: 0.8258 - val_f1: 0.4432 - val_loss: 0.6701
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 39ms/step - f1: 0.5902 - loss: 0.8130 - val_f1: 0.7354 - val_loss: 0.6696
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - f1: 0.6040 - loss: 0.7961
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.6338 - loss: 0.7937 - val_f1: 0.5880 - val_loss: 0.6564
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6466 - loss: 0.7822 - val_f1: 0.7610 - val_loss: 0.5873
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6699 - loss: 0.7435 - val_f1: 0.6739 - val_loss: 0.5541
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.7119 - loss: 0.7474 - val_f1: 0.6592 - val_loss: 0.6227
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7059 - loss: 0.7125 - val_f1: 0.7946 - val_loss: 0.5091
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7243 - loss: 0.7004 - val_f1: 0.5196 - val_loss: 0.7060
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7314 - loss: 0.6602 - val_f1: 0.7089 - val_loss: 0.5298
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7374 - loss: 0.6784 - val_f1: 0.8242 - val_loss: 0.4703
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7612 - loss: 0.6269 - val_f1: 0.6044 - val_loss: 0.6871
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7510 - loss: 0.7037 - val_f1: 0.8277 - val_loss: 0.4868
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7544 - loss: 0.6280 - val_f1: 0.7613 - val_loss: 0.5519
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7663 - loss: 0.6054 - val_f1: 0.4343 - val_loss: 0.6816
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.4249 - loss: 0.8440 - val_f1: 0.4395 - val_loss: 0.6906
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5022 - loss: 0.8278 - val_f1: 0.4586 - val_loss: 0.6469
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6366 - loss: 0.7710 - val_f1: 0.8610 - val_loss: 0.4210
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.7808 - loss: 0.5547 - val_f1: 0.8265 - val_loss: 0.4159
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7712 - loss: 0.6414 - val_f1: 0.7576 - val_loss: 0.4738
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7723 - loss: 0.6340 - val_f1: 0.8552 - val_loss: 0.4378
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.8144 - loss: 0.6005
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 27ms/step - f1: 0.7846 - loss: 0.6110 - val_f1: 0.7840 - val_loss: 0.5353
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 35ms/step - f1: 0.7812 - loss: 0.6024 - val_f1: 0.7469 - val_loss: 0.4780
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - f1: 0.8497 - loss: 0.5748
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7693 - loss: 0.5910 - val_f1: 0.8571 - val_loss: 0.4272
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.7918 - loss: 0.5809 - val_f1: 0.8674 - val_loss: 0.3651
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7848 - loss: 0.5993 - val_f1: 0.8493 - val_loss: 0.4862
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8175 - loss: 0.6421 - val_f1: 0.8588 - val_loss: 0.4274
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7717 - loss: 0.6251 - val_f1: 0.8512 - val_loss: 0.4158
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7860 - loss: 0.5740 - val_f1: 0.6897 - val_loss: 0.4793
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.8014 - loss: 0.6027 - val_f1: 0.8602 - val_loss: 0.4437
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7685 - loss: 0.5996 - val_f1: 0.8555 - val_loss: 0.3922
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8080 - loss: 0.5618 - val_f1: 0.8609 - val_loss: 0.4012
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8281 - loss: 0.5386 - val_f1: 0.8729 - val_loss: 0.3697
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7961 - loss: 0.5681 - val_f1: 0.7526 - val_loss: 0.4349
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8238 - loss: 0.5460 - val_f1: 0.8316 - val_loss: 0.3892
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7776 - loss: 0.5132 - val_f1: 0.7944 - val_loss: 0.4280
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8361 - loss: 0.4965 - val_f1: 0.8588 - val_loss: 0.3534
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8194 - loss: 0.5267 - val_f1: 0.8556 - val_loss: 0.3944
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8632 - loss: 0.4816 - val_f1: 0.8521 - val_loss: 0.4027
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8153 - loss: 0.5172 - val_f1: 0.8071 - val_loss: 0.4055
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8363 - loss: 0.4619 - val_f1: 0.8155 - val_loss: 0.3982
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.8725 - loss: 0.3784
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 5s 47ms/step - f1: 0.8154 - loss: 0.5080 - val_f1: 0.8538 - val_loss: 0.3505
Epoch 2/20
 91/100 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - f1: 0.8176 - loss: 0.4910
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8181 - loss: 0.4908 - val_f1: 0.8745 - val_loss: 0.3057
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7911 - loss: 0.5394 - val_f1: 0.8877 - val_loss: 0.3030
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8251 - loss: 0.4764 - val_f1: 0.8902 - val_loss: 0.2855
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8255 - loss: 0.5089 - val_f1: 0.8820 - val_loss: 0.3052
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8105 - loss: 0.5285 - val_f1: 0.8258 - val_loss: 0.3766
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8528 - loss: 0.4476 - val_f1: 0.8920 - val_loss: 0.2895
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8208 - loss: 0.4667 - val_f1: 0.8919 - val_loss: 0.2959
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8390 - loss: 0.4619 - val_f1: 0.8862 - val_loss: 0.3047
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8546 - loss: 0.4404 - val_f1: 0.8873 - val_loss: 0.2969
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8146 - loss: 0.5168 - val_f1: 0.8835 - val_loss: 0.2929
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8406 - loss: 0.4557 - val_f1: 0.8851 - val_loss: 0.3006
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.8449 - loss: 0.4423 - val_f1: 0.8880 - val_loss: 0.3117
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8555 - loss: 0.4340 - val_f1: 0.8828 - val_loss: 0.3109
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8567 - loss: 0.4272 - val_f1: 0.8788 - val_loss: 0.3086
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8447 - loss: 0.4364 - val_f1: 0.8540 - val_loss: 0.3341
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.8563 - loss: 0.4351 - val_f1: 0.8771 - val_loss: 0.3114
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8594 - loss: 0.4022 - val_f1: 0.8890 - val_loss: 0.2880
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.8553 - loss: 0.4136 - val_f1: 0.8857 - val_loss: 0.2923
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8523 - loss: 0.4189 - val_f1: 0.8809 - val_loss: 0.3006
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/tmp/ipykernel_18175/3169874832.py:50: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.
  val_scores_isCancerous = pd.concat([val_scores_isCancerous, new], ignore_index=True)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 33ms/step - f1: 0.5180 - loss: 0.8247 - val_f1: 0.7019 - val_loss: 0.6694
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6365 - loss: 0.7823 - val_f1: 0.7844 - val_loss: 0.5481
Epoch 3/20
  3/100 ━━━━━━━━━━━━━━━━━━━━ 1:11 733ms/step - f1: 0.7204 - loss: 0.6214
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6914 - loss: 0.6675 - val_f1: 0.2584 - val_loss: 0.9658
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6969 - loss: 0.7307 - val_f1: 0.7416 - val_loss: 0.4917
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7334 - loss: 0.6905 - val_f1: 0.7068 - val_loss: 0.5186
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7238 - loss: 0.6998 - val_f1: 0.8436 - val_loss: 0.5340
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7564 - loss: 0.6610 - val_f1: 0.8256 - val_loss: 0.5403
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7642 - loss: 0.6462 - val_f1: 0.7632 - val_loss: 0.4758
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7725 - loss: 0.5625 - val_f1: 0.7933 - val_loss: 0.5292
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7376 - loss: 0.6838 - val_f1: 0.8461 - val_loss: 0.4489
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7686 - loss: 0.6172 - val_f1: 0.8619 - val_loss: 0.3934
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.7921 - loss: 0.4926 - val_f1: 0.8668 - val_loss: 0.3779
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7787 - loss: 0.6104 - val_f1: 0.8636 - val_loss: 0.4103
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7677 - loss: 0.6246 - val_f1: 0.8576 - val_loss: 0.4137
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8270 - loss: 0.5412 - val_f1: 0.8519 - val_loss: 0.3721
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7723 - loss: 0.6052 - val_f1: 0.5529 - val_loss: 0.6117
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7846 - loss: 0.6004 - val_f1: 0.8575 - val_loss: 0.3854
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8020 - loss: 0.5548 - val_f1: 0.8804 - val_loss: 0.3805
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7904 - loss: 0.5623 - val_f1: 0.8418 - val_loss: 0.3712
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7890 - loss: 0.5647 - val_f1: 0.7986 - val_loss: 0.4317
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.8084 - loss: 0.6086
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 25ms/step - f1: 0.8048 - loss: 0.5745 - val_f1: 0.8096 - val_loss: 0.4291
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 36ms/step - f1: 0.8109 - loss: 0.5388 - val_f1: 0.7972 - val_loss: 0.4591
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - f1: 0.8519 - loss: 0.5350
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.8638 - loss: 0.4269 - val_f1: 0.8484 - val_loss: 0.4024
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8311 - loss: 0.4886 - val_f1: 0.8543 - val_loss: 0.3969
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8466 - loss: 0.4462 - val_f1: 0.8383 - val_loss: 0.3780
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.8247 - loss: 0.5135 - val_f1: 0.8050 - val_loss: 0.4750
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8568 - loss: 0.4296 - val_f1: 0.8414 - val_loss: 0.4004
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8475 - loss: 0.4560 - val_f1: 0.8451 - val_loss: 0.4021
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.7763 - loss: 0.5455 - val_f1: 0.8042 - val_loss: 0.4301
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8523 - loss: 0.4538 - val_f1: 0.7893 - val_loss: 0.5306
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.8467 - loss: 0.4380 - val_f1: 0.8508 - val_loss: 0.4002
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8772 - loss: 0.4183 - val_f1: 0.8529 - val_loss: 0.3752
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8620 - loss: 0.4103 - val_f1: 0.8122 - val_loss: 0.4330
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.8436 - loss: 0.4488 - val_f1: 0.8118 - val_loss: 0.4565
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8646 - loss: 0.4130 - val_f1: 0.8274 - val_loss: 0.3978
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8533 - loss: 0.4386 - val_f1: 0.8621 - val_loss: 0.3491
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8561 - loss: 0.4264 - val_f1: 0.8346 - val_loss: 0.3748
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.8304 - loss: 0.4401 - val_f1: 0.7805 - val_loss: 0.4430
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8587 - loss: 0.4367 - val_f1: 0.8496 - val_loss: 0.3619
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.8712 - loss: 0.3912 - val_f1: 0.8291 - val_loss: 0.4100
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.7512 - loss: 0.6268
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 26ms/step - f1: 0.8351 - loss: 0.4773 - val_f1: 0.8971 - val_loss: 0.2643
Epoch 2/20
 91/100 ━━━━━━━━━━━━━━━━━━━━ 0s 31ms/step - f1: 0.8430 - loss: 0.4567
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 34ms/step - f1: 0.8436 - loss: 0.4562 - val_f1: 0.8983 - val_loss: 0.2835
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8407 - loss: 0.4494 - val_f1: 0.8735 - val_loss: 0.3213
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8586 - loss: 0.4302 - val_f1: 0.8807 - val_loss: 0.3038
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8611 - loss: 0.4160 - val_f1: 0.8765 - val_loss: 0.3176
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8378 - loss: 0.4665 - val_f1: 0.8772 - val_loss: 0.3008
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.8645 - loss: 0.4030 - val_f1: 0.8737 - val_loss: 0.3038
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8420 - loss: 0.4146 - val_f1: 0.8957 - val_loss: 0.2690
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8564 - loss: 0.4126 - val_f1: 0.8878 - val_loss: 0.2855
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8606 - loss: 0.4120 - val_f1: 0.8929 - val_loss: 0.2875
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8563 - loss: 0.4037 - val_f1: 0.8946 - val_loss: 0.2962
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8671 - loss: 0.4136 - val_f1: 0.8897 - val_loss: 0.2894
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.8581 - loss: 0.4043 - val_f1: 0.8753 - val_loss: 0.3110
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8677 - loss: 0.3965 - val_f1: 0.8825 - val_loss: 0.2991
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8621 - loss: 0.3968 - val_f1: 0.8942 - val_loss: 0.2996
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8728 - loss: 0.3944 - val_f1: 0.8887 - val_loss: 0.2964
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.8615 - loss: 0.4161 - val_f1: 0.8971 - val_loss: 0.2725
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8814 - loss: 0.3779 - val_f1: 0.8500 - val_loss: 0.3479
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8752 - loss: 0.3558 - val_f1: 0.8864 - val_loss: 0.2876
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8612 - loss: 0.4066 - val_f1: 0.8924 - val_loss: 0.2747
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 7s 49ms/step - f1: 0.5232 - loss: 0.8249 - val_f1: 0.7947 - val_loss: 0.6335
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6717 - loss: 0.7582 - val_f1: 0.7016 - val_loss: 0.5385
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - f1: 0.6054 - loss: 0.7159
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7153 - loss: 0.7225 - val_f1: 0.6681 - val_loss: 0.5571
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6916 - loss: 0.7384 - val_f1: 0.4361 - val_loss: 0.6667
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6325 - loss: 0.7819 - val_f1: 0.8048 - val_loss: 0.5523
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7817 - loss: 0.6166 - val_f1: 0.8358 - val_loss: 0.5083
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7351 - loss: 0.6945 - val_f1: 0.7966 - val_loss: 0.5385
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7346 - loss: 0.6820 - val_f1: 0.7468 - val_loss: 0.4818
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7261 - loss: 0.7418 - val_f1: 0.6016 - val_loss: 0.6448
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7661 - loss: 0.6294 - val_f1: 0.8296 - val_loss: 0.4425
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7708 - loss: 0.6220 - val_f1: 0.7765 - val_loss: 0.4427
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7126 - loss: 0.6626 - val_f1: 0.8115 - val_loss: 0.4898
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7659 - loss: 0.6254 - val_f1: 0.8096 - val_loss: 0.4798
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7875 - loss: 0.5900 - val_f1: 0.8564 - val_loss: 0.4122
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7894 - loss: 0.6609 - val_f1: 0.5899 - val_loss: 0.7503
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7651 - loss: 0.6161 - val_f1: 0.8152 - val_loss: 0.4749
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7719 - loss: 0.6263 - val_f1: 0.8606 - val_loss: 0.3963
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7767 - loss: 0.5827 - val_f1: 0.7720 - val_loss: 0.5260
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7956 - loss: 0.5557 - val_f1: 0.8716 - val_loss: 0.3918
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7924 - loss: 0.5630 - val_f1: 0.8624 - val_loss: 0.3840
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.7865 - loss: 0.6888
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 42ms/step - f1: 0.7971 - loss: 0.5887 - val_f1: 0.8708 - val_loss: 0.3852
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8002 - loss: 0.5535 - val_f1: 0.8326 - val_loss: 0.3691
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - f1: 0.8465 - loss: 0.4339
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8533 - loss: 0.4139 - val_f1: 0.8034 - val_loss: 0.4025
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8208 - loss: 0.5204 - val_f1: 0.8345 - val_loss: 0.3722
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7880 - loss: 0.5578 - val_f1: 0.8722 - val_loss: 0.3538
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.8153 - loss: 0.5134 - val_f1: 0.8542 - val_loss: 0.3508
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8242 - loss: 0.5107 - val_f1: 0.8593 - val_loss: 0.3690
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8187 - loss: 0.5414 - val_f1: 0.7674 - val_loss: 0.5212
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.8035 - loss: 0.4523 - val_f1: 0.7972 - val_loss: 0.4737
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8399 - loss: 0.4817 - val_f1: 0.8353 - val_loss: 0.3825
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8343 - loss: 0.4887 - val_f1: 0.8335 - val_loss: 0.4358
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.9262 - loss: 0.4148 - val_f1: 0.8406 - val_loss: 0.4041
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8451 - loss: 0.4745 - val_f1: 0.7549 - val_loss: 0.5322
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8560 - loss: 0.4405 - val_f1: 0.8474 - val_loss: 0.3984
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.9137 - loss: 0.4025 - val_f1: 0.8377 - val_loss: 0.4072
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8391 - loss: 0.4701 - val_f1: 0.8358 - val_loss: 0.4010
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8585 - loss: 0.4478 - val_f1: 0.8597 - val_loss: 0.3487
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.9256 - loss: 0.3038 - val_f1: 0.8527 - val_loss: 0.3530
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8509 - loss: 0.4480 - val_f1: 0.8741 - val_loss: 0.3338
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8443 - loss: 0.4549 - val_f1: 0.8658 - val_loss: 0.3362
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.9498 - loss: 0.3393
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 27ms/step - f1: 0.8680 - loss: 0.4282 - val_f1: 0.8479 - val_loss: 0.3446
Epoch 2/20
 91/100 ━━━━━━━━━━━━━━━━━━━━ 0s 34ms/step - f1: 0.8312 - loss: 0.4720
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 37ms/step - f1: 0.8300 - loss: 0.4742 - val_f1: 0.8997 - val_loss: 0.2917
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8178 - loss: 0.4882 - val_f1: 0.7293 - val_loss: 0.5273
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8243 - loss: 0.4645 - val_f1: 0.8856 - val_loss: 0.2871
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.8255 - loss: 0.4562 - val_f1: 0.8966 - val_loss: 0.2725
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8494 - loss: 0.4183 - val_f1: 0.8434 - val_loss: 0.3600
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8517 - loss: 0.4306 - val_f1: 0.8851 - val_loss: 0.3071
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8496 - loss: 0.4277 - val_f1: 0.8651 - val_loss: 0.3295
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8401 - loss: 0.4496 - val_f1: 0.8227 - val_loss: 0.3886
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8464 - loss: 0.4242 - val_f1: 0.8717 - val_loss: 0.3140
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8618 - loss: 0.4074 - val_f1: 0.8891 - val_loss: 0.3039
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8489 - loss: 0.4252 - val_f1: 0.8766 - val_loss: 0.3017
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8676 - loss: 0.3832 - val_f1: 0.8357 - val_loss: 0.3766
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8545 - loss: 0.4145 - val_f1: 0.8904 - val_loss: 0.2875
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.8540 - loss: 0.4123 - val_f1: 0.8859 - val_loss: 0.2981
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8625 - loss: 0.3989 - val_f1: 0.8776 - val_loss: 0.3168
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8581 - loss: 0.3945 - val_f1: 0.8662 - val_loss: 0.3182
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8674 - loss: 0.3964 - val_f1: 0.8500 - val_loss: 0.3522
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8780 - loss: 0.3855 - val_f1: 0.8118 - val_loss: 0.4480
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8648 - loss: 0.3857 - val_f1: 0.8907 - val_loss: 0.2868
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 5s 33ms/step - f1: 0.5385 - loss: 0.8281 - val_f1: 0.5974 - val_loss: 0.6937
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 35ms/step - f1: 0.6060 - loss: 0.8064 - val_f1: 0.4343 - val_loss: 0.6784
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 10ms/step - f1: 0.3120 - loss: 0.9655
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.3679 - loss: 0.9064 - val_f1: 0.4436 - val_loss: 0.6868
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6001 - loss: 0.8025 - val_f1: 0.7602 - val_loss: 0.5754
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6397 - loss: 0.7721 - val_f1: 0.4830 - val_loss: 0.8703
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5884 - loss: 1.0130 - val_f1: 0.6328 - val_loss: 0.5687
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6923 - loss: 0.7436 - val_f1: 0.7567 - val_loss: 0.5210
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7275 - loss: 0.6906 - val_f1: 0.7666 - val_loss: 0.4906
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8133 - loss: 0.6096 - val_f1: 0.7828 - val_loss: 0.5387
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 25ms/step - f1: 0.7456 - loss: 0.6649 - val_f1: 0.8474 - val_loss: 0.4245
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7641 - loss: 0.6288 - val_f1: 0.7395 - val_loss: 0.4939
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6838 - loss: 0.6730 - val_f1: 0.8162 - val_loss: 0.4745
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7753 - loss: 0.6390 - val_f1: 0.7429 - val_loss: 0.4681
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7719 - loss: 0.6066 - val_f1: 0.7777 - val_loss: 0.4562
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8535 - loss: 0.5498 - val_f1: 0.8094 - val_loss: 0.4194
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7617 - loss: 0.6227 - val_f1: 0.8564 - val_loss: 0.4059
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7726 - loss: 0.6095 - val_f1: 0.6655 - val_loss: 0.5967
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.7113 - loss: 0.6177 - val_f1: 0.8681 - val_loss: 0.4081
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7801 - loss: 0.5767 - val_f1: 0.8254 - val_loss: 0.3771
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7928 - loss: 0.5676 - val_f1: 0.8727 - val_loss: 0.3489
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.8239 - loss: 0.4865
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 25ms/step - f1: 0.8075 - loss: 0.5382 - val_f1: 0.7247 - val_loss: 0.4984
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 34ms/step - f1: 0.8209 - loss: 0.5357 - val_f1: 0.8444 - val_loss: 0.4519
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - f1: 0.6337 - loss: 0.7488
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6849 - loss: 0.7327 - val_f1: 0.7829 - val_loss: 0.4647
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8100 - loss: 0.5550 - val_f1: 0.8604 - val_loss: 0.3864
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8231 - loss: 0.5055 - val_f1: 0.8389 - val_loss: 0.3690
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.8024 - loss: 0.4773 - val_f1: 0.8559 - val_loss: 0.3567
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8248 - loss: 0.4986 - val_f1: 0.8516 - val_loss: 0.3679
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8249 - loss: 0.4898 - val_f1: 0.8461 - val_loss: 0.3544
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8660 - loss: 0.4071 - val_f1: 0.7745 - val_loss: 0.4714
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8500 - loss: 0.4498 - val_f1: 0.8304 - val_loss: 0.3801
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8554 - loss: 0.4519 - val_f1: 0.8528 - val_loss: 0.3480
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.9386 - loss: 0.3137 - val_f1: 0.8366 - val_loss: 0.3714
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8546 - loss: 0.4515 - val_f1: 0.8451 - val_loss: 0.4114
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8453 - loss: 0.4486 - val_f1: 0.7244 - val_loss: 0.5684
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8514 - loss: 0.3606 - val_f1: 0.8599 - val_loss: 0.3511
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8531 - loss: 0.4429 - val_f1: 0.8303 - val_loss: 0.3787
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8629 - loss: 0.4392 - val_f1: 0.8477 - val_loss: 0.3585
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8400 - loss: 0.3953 - val_f1: 0.8268 - val_loss: 0.3897
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.8619 - loss: 0.4297 - val_f1: 0.8675 - val_loss: 0.3361
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8490 - loss: 0.4209 - val_f1: 0.8538 - val_loss: 0.3710
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.8776 - loss: 0.4234
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 27ms/step - f1: 0.8601 - loss: 0.4168 - val_f1: 0.8972 - val_loss: 0.2649
Epoch 2/20
 92/100 ━━━━━━━━━━━━━━━━━━━━ 0s 30ms/step - f1: 0.8319 - loss: 0.4626
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 33ms/step - f1: 0.8332 - loss: 0.4609 - val_f1: 0.8883 - val_loss: 0.2895
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8462 - loss: 0.4219 - val_f1: 0.8939 - val_loss: 0.2873
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8596 - loss: 0.4190 - val_f1: 0.8862 - val_loss: 0.3040
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 24ms/step - f1: 0.8467 - loss: 0.4337 - val_f1: 0.8882 - val_loss: 0.2799
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8599 - loss: 0.4143 - val_f1: 0.8895 - val_loss: 0.2867
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8556 - loss: 0.4365 - val_f1: 0.8580 - val_loss: 0.3249
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8624 - loss: 0.4155 - val_f1: 0.8962 - val_loss: 0.2709
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8737 - loss: 0.3822 - val_f1: 0.8937 - val_loss: 0.2856
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8557 - loss: 0.4127 - val_f1: 0.8907 - val_loss: 0.2819
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8571 - loss: 0.3956 - val_f1: 0.8579 - val_loss: 0.3155
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8582 - loss: 0.4053 - val_f1: 0.8683 - val_loss: 0.3210
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8613 - loss: 0.4026 - val_f1: 0.8904 - val_loss: 0.3091
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8672 - loss: 0.4068 - val_f1: 0.8851 - val_loss: 0.2835
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8661 - loss: 0.4032 - val_f1: 0.8974 - val_loss: 0.2782
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8701 - loss: 0.3974 - val_f1: 0.8687 - val_loss: 0.3286
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8740 - loss: 0.3885 - val_f1: 0.9022 - val_loss: 0.2739
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.8718 - loss: 0.3680 - val_f1: 0.8970 - val_loss: 0.3062
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.8636 - loss: 0.4064 - val_f1: 0.8930 - val_loss: 0.2894
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.8672 - loss: 0.4009 - val_f1: 0.8430 - val_loss: 0.3629
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 7s 49ms/step - f1: 0.5534 - loss: 1.6201 - val_f1: 0.5687 - val_loss: 1.3905
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5441 - loss: 1.4835 - val_f1: 0.4458 - val_loss: 1.2168
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - f1: 0.6601 - loss: 1.3152
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6443 - loss: 1.3385 - val_f1: 0.5763 - val_loss: 1.2069
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6041 - loss: 1.3304 - val_f1: 0.5750 - val_loss: 1.0613
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.6891 - loss: 1.1813 - val_f1: 0.6316 - val_loss: 0.9683
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6165 - loss: 1.1647 - val_f1: 0.6881 - val_loss: 0.9437
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6687 - loss: 1.1296 - val_f1: 0.7459 - val_loss: 0.8634
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6960 - loss: 1.0383 - val_f1: 0.6828 - val_loss: 0.8370
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6118 - loss: 1.0526 - val_f1: 0.6360 - val_loss: 0.8627
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7110 - loss: 0.9677 - val_f1: 0.8104 - val_loss: 0.7074
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7167 - loss: 0.9222 - val_f1: 0.8321 - val_loss: 0.7178
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7741 - loss: 0.8550 - val_f1: 0.7644 - val_loss: 0.7087
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7280 - loss: 0.8695 - val_f1: 0.5744 - val_loss: 0.8161
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7494 - loss: 0.8415 - val_f1: 0.5145 - val_loss: 0.8564
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6743 - loss: 0.9548 - val_f1: 0.6283 - val_loss: 0.7664
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7382 - loss: 0.8118 - val_f1: 0.7636 - val_loss: 0.6101
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7312 - loss: 0.7947 - val_f1: 0.6788 - val_loss: 0.6530
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6300 - loss: 0.9017 - val_f1: 0.8246 - val_loss: 0.6071
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7350 - loss: 0.7536 - val_f1: 0.8513 - val_loss: 0.5749
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7423 - loss: 0.7451 - val_f1: 0.7928 - val_loss: 0.6037
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  8/100 ━━━━━━━━━━━━━━━━━━━━ 1s 17ms/step - f1: 0.7763 - loss: 0.7179
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 40ms/step - f1: 0.7641 - loss: 0.7370 - val_f1: 0.7611 - val_loss: 0.6184
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7836 - loss: 0.7026 - val_f1: 0.7823 - val_loss: 0.5817
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 9ms/step - f1: 0.6854 - loss: 0.6947
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5977 - loss: 0.8603 - val_f1: 0.8028 - val_loss: 0.5222
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7686 - loss: 0.7106 - val_f1: 0.8519 - val_loss: 0.5143
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7496 - loss: 0.7255 - val_f1: 0.8406 - val_loss: 0.5789
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.7412 - loss: 0.7586 - val_f1: 0.8228 - val_loss: 0.5951
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7442 - loss: 0.7250 - val_f1: 0.8516 - val_loss: 0.5426
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7602 - loss: 0.6890 - val_f1: 0.6428 - val_loss: 0.6863
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7546 - loss: 0.6903 - val_f1: 0.7801 - val_loss: 0.5186
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7583 - loss: 0.6931 - val_f1: 0.7901 - val_loss: 0.5094
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7611 - loss: 0.6951 - val_f1: 0.8465 - val_loss: 0.5136
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8587 - loss: 0.5862 - val_f1: 0.7739 - val_loss: 0.5228
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7459 - loss: 0.6993 - val_f1: 0.8563 - val_loss: 0.4786
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7537 - loss: 0.7040 - val_f1: 0.8284 - val_loss: 0.5314
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6457 - loss: 0.7417 - val_f1: 0.7255 - val_loss: 0.5478
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7389 - loss: 0.7250 - val_f1: 0.7926 - val_loss: 0.5149
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7378 - loss: 0.7189 - val_f1: 0.8579 - val_loss: 0.4703
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7270 - loss: 0.7807 - val_f1: 0.7626 - val_loss: 0.5155
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7485 - loss: 0.7015 - val_f1: 0.6010 - val_loss: 0.8011
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.7481 - loss: 0.7242 - val_f1: 0.7458 - val_loss: 0.6050
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.7137 - loss: 0.7651
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 42ms/step - f1: 0.7616 - loss: 0.7118 - val_f1: 0.5434 - val_loss: 0.7929
Epoch 2/20
 92/100 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - f1: 0.7389 - loss: 0.7109
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7399 - loss: 0.7106 - val_f1: 0.7689 - val_loss: 0.5569
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7706 - loss: 0.6857 - val_f1: 0.3852 - val_loss: 1.0918
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.6447 - loss: 0.8605 - val_f1: 0.7389 - val_loss: 0.5717
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7520 - loss: 0.7115 - val_f1: 0.6795 - val_loss: 0.6044
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7130 - loss: 0.7418 - val_f1: 0.4602 - val_loss: 0.7231
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6463 - loss: 0.8288 - val_f1: 0.7624 - val_loss: 0.5575
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7875 - loss: 0.6816 - val_f1: 0.7709 - val_loss: 0.5403
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7568 - loss: 0.6876 - val_f1: 0.7672 - val_loss: 0.5492
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.7437 - loss: 0.7199 - val_f1: 0.7565 - val_loss: 0.5516
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7751 - loss: 0.6871 - val_f1: 0.8171 - val_loss: 0.5132
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.7523 - loss: 0.7300 - val_f1: 0.7857 - val_loss: 0.5365
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7514 - loss: 0.7012 - val_f1: 0.8238 - val_loss: 0.5055
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.7548 - loss: 0.7140 - val_f1: 0.6289 - val_loss: 0.7067
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7250 - loss: 0.7586 - val_f1: 0.5960 - val_loss: 0.7565
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7153 - loss: 0.7877 - val_f1: 0.7158 - val_loss: 0.5928
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7517 - loss: 0.7084 - val_f1: 0.7925 - val_loss: 0.5550
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7664 - loss: 0.7034 - val_f1: 0.7425 - val_loss: 0.5535
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7713 - loss: 0.6815 - val_f1: 0.7069 - val_loss: 0.5888
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.7563 - loss: 0.7051 - val_f1: 0.6816 - val_loss: 0.6468
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 7s 48ms/step - f1: 0.5490 - loss: 1.5939 - val_f1: 0.7765 - val_loss: 1.2384
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5665 - loss: 1.3292 - val_f1: 0.7250 - val_loss: 0.9820
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 7ms/step - f1: 0.7314 - loss: 1.1307
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6817 - loss: 1.1385 - val_f1: 0.7346 - val_loss: 0.9798
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6609 - loss: 1.1146 - val_f1: 0.8051 - val_loss: 0.9149
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.6496 - loss: 1.0169 - val_f1: 0.5265 - val_loss: 0.8564
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6895 - loss: 0.9758 - val_f1: 0.8044 - val_loss: 0.7584
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6930 - loss: 0.9092 - val_f1: 0.7852 - val_loss: 0.6959
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7058 - loss: 0.8402 - val_f1: 0.4378 - val_loss: 0.7744
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.4870 - loss: 0.9071 - val_f1: 0.4387 - val_loss: 0.7709
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6031 - loss: 0.8599 - val_f1: 0.7020 - val_loss: 0.6208
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5613 - loss: 0.8788 - val_f1: 0.4343 - val_loss: 0.7255
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.3839 - loss: 0.9112 - val_f1: 0.4343 - val_loss: 0.7334
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5678 - loss: 0.8567 - val_f1: 0.5499 - val_loss: 0.6987
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7140 - loss: 0.7533 - val_f1: 0.8359 - val_loss: 0.5683
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6556 - loss: 0.8073 - val_f1: 0.8405 - val_loss: 0.5618
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7155 - loss: 0.7511 - val_f1: 0.8431 - val_loss: 0.5464
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7364 - loss: 0.7263 - val_f1: 0.4343 - val_loss: 0.7449
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.3545 - loss: 1.0261 - val_f1: 0.4343 - val_loss: 0.7384
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4868 - loss: 0.8796 - val_f1: 0.4415 - val_loss: 0.7237
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5042 - loss: 0.8546 - val_f1: 0.5253 - val_loss: 0.7091
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.5617 - loss: 0.8355
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 27ms/step - f1: 0.5295 - loss: 0.8335 - val_f1: 0.3200 - val_loss: 0.7132
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 33ms/step - f1: 0.6958 - loss: 0.7558 - val_f1: 0.6632 - val_loss: 0.6469
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - f1: 0.5438 - loss: 0.7870
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5951 - loss: 0.7860 - val_f1: 0.5953 - val_loss: 0.6641
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7022 - loss: 0.7533 - val_f1: 0.6466 - val_loss: 0.6784
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6611 - loss: 0.7902 - val_f1: 0.7267 - val_loss: 0.6187
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.8393 - loss: 0.5883 - val_f1: 0.8364 - val_loss: 0.5421
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6971 - loss: 0.7696 - val_f1: 0.8171 - val_loss: 0.5797
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7476 - loss: 0.7127 - val_f1: 0.4271 - val_loss: 0.9743
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7166 - loss: 0.7888 - val_f1: 0.7658 - val_loss: 0.5616
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6565 - loss: 0.7898 - val_f1: 0.4821 - val_loss: 0.7118
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5071 - loss: 0.8565 - val_f1: 0.4821 - val_loss: 0.6797
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5930 - loss: 0.8169 - val_f1: 0.4821 - val_loss: 0.6696
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5011 - loss: 0.8428 - val_f1: 0.7004 - val_loss: 0.5812
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7185 - loss: 0.7287 - val_f1: 0.8073 - val_loss: 0.5652
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.7188 - loss: 0.7296 - val_f1: 0.7899 - val_loss: 0.5406
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7089 - loss: 0.7502 - val_f1: 0.5065 - val_loss: 0.7012
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6381 - loss: 0.7942 - val_f1: 0.6023 - val_loss: 0.6328
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5415 - loss: 0.8172 - val_f1: 0.6549 - val_loss: 0.6141
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7448 - loss: 0.7317 - val_f1: 0.8499 - val_loss: 0.5175
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7003 - loss: 0.7652 - val_f1: 0.6243 - val_loss: 0.7258
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.5887 - loss: 0.8570
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 41ms/step - f1: 0.6071 - loss: 0.8368 - val_f1: 0.7892 - val_loss: 0.5828
Epoch 2/20
 94/100 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - f1: 0.7006 - loss: 0.7579
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 18ms/step - f1: 0.6960 - loss: 0.7613 - val_f1: 0.5689 - val_loss: 0.7197
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5805 - loss: 0.8371 - val_f1: 0.7285 - val_loss: 0.5856
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5737 - loss: 0.8337 - val_f1: 0.4701 - val_loss: 0.7156
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5154 - loss: 0.8416 - val_f1: 0.5069 - val_loss: 0.7095
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5228 - loss: 0.8270 - val_f1: 0.4706 - val_loss: 0.6981
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5473 - loss: 0.8204 - val_f1: 0.4551 - val_loss: 0.6918
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.4879 - loss: 0.8368 - val_f1: 0.4551 - val_loss: 0.6985
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4559 - loss: 0.8394 - val_f1: 0.2245 - val_loss: 0.7060
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5097 - loss: 0.8262 - val_f1: 0.4551 - val_loss: 0.6900
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4472 - loss: 0.8293 - val_f1: 0.4582 - val_loss: 0.6979
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5009 - loss: 0.8159 - val_f1: 0.4551 - val_loss: 0.6879
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4810 - loss: 0.8191 - val_f1: 0.4551 - val_loss: 0.6882
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5257 - loss: 0.8069 - val_f1: 0.6616 - val_loss: 0.6776
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5929 - loss: 0.8076 - val_f1: 0.2245 - val_loss: 0.7027
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.4746 - loss: 0.8288 - val_f1: 0.6617 - val_loss: 0.6983
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.5689 - loss: 0.8133 - val_f1: 0.4672 - val_loss: 0.6944
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5865 - loss: 0.8106 - val_f1: 0.4612 - val_loss: 0.6992
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5213 - loss: 0.8261 - val_f1: 0.2245 - val_loss: 0.7055
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.5469 - loss: 0.8086 - val_f1: 0.7927 - val_loss: 0.5930
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 5s 32ms/step - f1: 0.5297 - loss: 1.6286 - val_f1: 0.4519 - val_loss: 1.3474
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 34ms/step - f1: 0.6379 - loss: 1.4527 - val_f1: 0.6149 - val_loss: 1.1905
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 6ms/step - f1: 0.5679 - loss: 1.3941
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6298 - loss: 1.3422 - val_f1: 0.8043 - val_loss: 1.1726
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6637 - loss: 1.3039 - val_f1: 0.4660 - val_loss: 1.1732
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.6894 - loss: 1.1846 - val_f1: 0.8231 - val_loss: 0.9370
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7043 - loss: 1.1082 - val_f1: 0.7993 - val_loss: 0.9507
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7052 - loss: 1.0688 - val_f1: 0.7900 - val_loss: 0.8365
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7003 - loss: 1.0291 - val_f1: 0.7120 - val_loss: 0.8139
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.6708 - loss: 1.0094 - val_f1: 0.8297 - val_loss: 0.8115
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 25ms/step - f1: 0.7182 - loss: 0.9583 - val_f1: 0.7469 - val_loss: 0.7185
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 28ms/step - f1: 0.7038 - loss: 0.9215 - val_f1: 0.7666 - val_loss: 0.6836
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 7ms/step - f1: 0.7568 - loss: 0.7528 - val_f1: 0.7578 - val_loss: 0.6805
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 27ms/step - f1: 0.7098 - loss: 0.8779 - val_f1: 0.6802 - val_loss: 0.7225
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.7188 - loss: 0.8499 - val_f1: 0.5877 - val_loss: 0.7710
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.6983 - loss: 0.9027 - val_f1: 0.3538 - val_loss: 0.9396
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7315 - loss: 0.8202 - val_f1: 0.6674 - val_loss: 0.6850
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7389 - loss: 0.7951 - val_f1: 0.8312 - val_loss: 0.6115
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7341 - loss: 0.7564 - val_f1: 0.8209 - val_loss: 0.5864
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7291 - loss: 0.7815 - val_f1: 0.8310 - val_loss: 0.6407
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7629 - loss: 0.7486 - val_f1: 0.7888 - val_loss: 0.5352
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  8/100 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - f1: 0.7917 - loss: 0.6598
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 30ms/step - f1: 0.7429 - loss: 0.7367 - val_f1: 0.8554 - val_loss: 0.5358
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 36ms/step - f1: 0.7418 - loss: 0.7451 - val_f1: 0.8544 - val_loss: 0.5532
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - f1: 0.8519 - loss: 0.6211
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.8288 - loss: 0.6732 - val_f1: 0.8528 - val_loss: 0.5480
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7834 - loss: 0.7018 - val_f1: 0.8542 - val_loss: 0.5168
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7648 - loss: 0.7079 - val_f1: 0.8543 - val_loss: 0.5186
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.6697 - loss: 0.8306 - val_f1: 0.8122 - val_loss: 0.5191
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7616 - loss: 0.7184 - val_f1: 0.7459 - val_loss: 0.5818
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7513 - loss: 0.7257 - val_f1: 0.7680 - val_loss: 0.5448
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7883 - loss: 0.6823 - val_f1: 0.8368 - val_loss: 0.5525
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7586 - loss: 0.6840 - val_f1: 0.8432 - val_loss: 0.5267
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7344 - loss: 0.7061 - val_f1: 0.7044 - val_loss: 0.5528
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.7684 - loss: 0.6839 - val_f1: 0.8268 - val_loss: 0.5135
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7591 - loss: 0.6882 - val_f1: 0.8536 - val_loss: 0.5209
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7457 - loss: 0.7169 - val_f1: 0.7911 - val_loss: 0.5151
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.7180 - loss: 0.6114 - val_f1: 0.8425 - val_loss: 0.4900
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7375 - loss: 0.7195 - val_f1: 0.7990 - val_loss: 0.5131
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7554 - loss: 0.6970 - val_f1: 0.8306 - val_loss: 0.4555
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.8511 - loss: 0.5274 - val_f1: 0.7998 - val_loss: 0.5433
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7545 - loss: 0.6871 - val_f1: 0.7998 - val_loss: 0.5786
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7461 - loss: 0.7066 - val_f1: 0.8550 - val_loss: 0.5027
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - f1: 0.8177 - loss: 0.6653
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 41ms/step - f1: 0.7763 - loss: 0.7046 - val_f1: 0.7341 - val_loss: 0.5939
Epoch 2/20
 94/100 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - f1: 0.7515 - loss: 0.7020
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7513 - loss: 0.7026 - val_f1: 0.7952 - val_loss: 0.5184
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7646 - loss: 0.6889 - val_f1: 0.8169 - val_loss: 0.5162
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.7724 - loss: 0.6852 - val_f1: 0.7065 - val_loss: 0.5945
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7622 - loss: 0.6869 - val_f1: 0.7679 - val_loss: 0.5322
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7533 - loss: 0.7008 - val_f1: 0.7560 - val_loss: 0.5817
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7564 - loss: 0.6937 - val_f1: 0.6708 - val_loss: 0.6339
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.7582 - loss: 0.6789 - val_f1: 0.7152 - val_loss: 0.5979
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7457 - loss: 0.7052 - val_f1: 0.7935 - val_loss: 0.5224
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.7714 - loss: 0.6855 - val_f1: 0.6997 - val_loss: 0.6225
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7622 - loss: 0.7254 - val_f1: 0.8123 - val_loss: 0.5013
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.7568 - loss: 0.7048 - val_f1: 0.7165 - val_loss: 0.5887
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7666 - loss: 0.6630 - val_f1: 0.6491 - val_loss: 0.7060
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.7536 - loss: 0.6941 - val_f1: 0.8109 - val_loss: 0.5048
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7741 - loss: 0.7021 - val_f1: 0.7957 - val_loss: 0.5246
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 19ms/step - f1: 0.7716 - loss: 0.6872 - val_f1: 0.6560 - val_loss: 0.6500
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.7601 - loss: 0.6837 - val_f1: 0.7788 - val_loss: 0.5308
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7397 - loss: 0.7191 - val_f1: 0.6358 - val_loss: 0.6952
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.7645 - loss: 0.6898 - val_f1: 0.6616 - val_loss: 0.6691
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.7348 - loss: 0.7167 - val_f1: 0.4551 - val_loss: 0.7511
Found 5460 validated image filenames belonging to 4 classes.
Found 2613 validated image filenames belonging to 4 classes.
Found 5460 validated image filenames belonging to 2 classes.
Found 2613 validated image filenames belonging to 2 classes.
Epoch 1/20
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 6s 33ms/step - f1: 0.5278 - loss: 1.5989 - val_f1: 0.4343 - val_loss: 1.2391
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 35ms/step - f1: 0.5729 - loss: 1.3383 - val_f1: 0.4343 - val_loss: 1.0692
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - f1: 0.4865 - loss: 1.1921
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.4863 - loss: 1.1932 - val_f1: 0.4343 - val_loss: 1.0644
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4736 - loss: 1.1595 - val_f1: 0.4343 - val_loss: 0.9378
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4820 - loss: 1.0402 - val_f1: 0.2414 - val_loss: 0.8647
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.2353 - loss: 0.9905 - val_f1: 0.2414 - val_loss: 0.8626
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4776 - loss: 0.9664 - val_f1: 0.4343 - val_loss: 0.8000
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4743 - loss: 0.9141 - val_f1: 0.2414 - val_loss: 0.7676
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.3217 - loss: 0.8996 - val_f1: 0.2414 - val_loss: 0.7703
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.3926 - loss: 0.8844 - val_f1: 0.4343 - val_loss: 0.7375
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4667 - loss: 0.8592 - val_f1: 0.2414 - val_loss: 0.7285
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.1350 - loss: 0.8240 - val_f1: 0.2414 - val_loss: 0.7286
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.4836 - loss: 0.8409 - val_f1: 0.4343 - val_loss: 0.7076
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4759 - loss: 0.8311 - val_f1: 0.4343 - val_loss: 0.6999
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.4109 - loss: 0.8487 - val_f1: 0.4343 - val_loss: 0.7017
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4916 - loss: 0.8293 - val_f1: 0.4343 - val_loss: 0.6978
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4666 - loss: 0.8235 - val_f1: 0.4343 - val_loss: 0.6935
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 0s 5ms/step - f1: 0.5165 - loss: 0.8041 - val_f1: 0.4343 - val_loss: 0.6931
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4777 - loss: 0.8164 - val_f1: 0.4343 - val_loss: 0.6856
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4665 - loss: 0.8196 - val_f1: 0.4343 - val_loss: 0.6837
Found 5468 validated image filenames belonging to 4 classes.
Found 2605 validated image filenames belonging to 4 classes.
Found 5468 validated image filenames belonging to 2 classes.
Found 2605 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.3901 - loss: 0.8547
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 42ms/step - f1: 0.4816 - loss: 0.8287 - val_f1: 0.2035 - val_loss: 0.6980
Epoch 2/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4610 - loss: 0.8229 - val_f1: 0.4821 - val_loss: 0.6916
Epoch 3/20
  1/100 ━━━━━━━━━━━━━━━━━━━━ 0s 4ms/step - f1: 0.4865 - loss: 0.8104
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.5646 - loss: 0.7886 - val_f1: 0.4821 - val_loss: 0.6885
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 25ms/step - f1: 0.4715 - loss: 0.8278 - val_f1: 0.4821 - val_loss: 0.6934
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 24ms/step - f1: 0.4959 - loss: 0.8241 - val_f1: 0.2035 - val_loss: 0.7022
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.1673 - loss: 0.8057 - val_f1: 0.2035 - val_loss: 0.7010
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 24ms/step - f1: 0.4665 - loss: 0.8188 - val_f1: 0.2035 - val_loss: 0.7099
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 24ms/step - f1: 0.4074 - loss: 0.8222 - val_f1: 0.4821 - val_loss: 0.6891
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 6ms/step - f1: 0.4419 - loss: 0.8217 - val_f1: 0.4821 - val_loss: 0.6926
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 25ms/step - f1: 0.3690 - loss: 0.8234 - val_f1: 0.4821 - val_loss: 0.6921
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4922 - loss: 0.8173 - val_f1: 0.2035 - val_loss: 0.6942
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.2111 - loss: 0.8144 - val_f1: 0.2035 - val_loss: 0.6943
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4318 - loss: 0.8216 - val_f1: 0.2035 - val_loss: 0.6974
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4635 - loss: 0.8213 - val_f1: 0.2035 - val_loss: 0.6945
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.5209 - loss: 0.8107 - val_f1: 0.4821 - val_loss: 0.6915
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4792 - loss: 0.8264 - val_f1: 0.4821 - val_loss: 0.6854
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.4799 - loss: 0.8198 - val_f1: 0.2035 - val_loss: 0.7168
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 1s 5ms/step - f1: 0.2743 - loss: 0.8308 - val_f1: 0.2035 - val_loss: 0.7199
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.2442 - loss: 0.8263 - val_f1: 0.4821 - val_loss: 0.6890
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 24ms/step - f1: 0.4791 - loss: 0.8254 - val_f1: 0.2035 - val_loss: 0.6938
Found 5218 validated image filenames belonging to 4 classes.
Found 2855 validated image filenames belonging to 4 classes.
Found 5218 validated image filenames belonging to 2 classes.
Found 2855 validated image filenames belonging to 2 classes.
Epoch 1/20
  5/100 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - f1: 0.2468 - loss: 0.8188
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 42ms/step - f1: 0.4933 - loss: 0.8187 - val_f1: 0.4551 - val_loss: 0.6920
Epoch 2/20
 93/100 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - f1: 0.4891 - loss: 0.8154
/home/fast/aiti/ML_Assignment2/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.
  self._interrupted_warning()
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4894 - loss: 0.8155 - val_f1: 0.4551 - val_loss: 0.6870
Epoch 3/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4878 - loss: 0.8151 - val_f1: 0.2245 - val_loss: 0.6938
Epoch 4/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4891 - loss: 0.8174 - val_f1: 0.4551 - val_loss: 0.6831
Epoch 5/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.5089 - loss: 0.8060 - val_f1: 0.4551 - val_loss: 0.6887
Epoch 6/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.5026 - loss: 0.8187 - val_f1: 0.4551 - val_loss: 0.6840
Epoch 7/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4598 - loss: 0.8174 - val_f1: 0.4551 - val_loss: 0.6810
Epoch 8/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4872 - loss: 0.8243 - val_f1: 0.4551 - val_loss: 0.6861
Epoch 9/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4913 - loss: 0.8231 - val_f1: 0.4551 - val_loss: 0.6801
Epoch 10/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4747 - loss: 0.8180 - val_f1: 0.4551 - val_loss: 0.6843
Epoch 11/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.4841 - loss: 0.8232 - val_f1: 0.4551 - val_loss: 0.6869
Epoch 12/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4995 - loss: 0.8171 - val_f1: 0.4551 - val_loss: 0.6846
Epoch 13/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 23ms/step - f1: 0.4651 - loss: 0.8153 - val_f1: 0.2245 - val_loss: 0.6945
Epoch 14/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4582 - loss: 0.8165 - val_f1: 0.4551 - val_loss: 0.6889
Epoch 15/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4680 - loss: 0.8178 - val_f1: 0.2245 - val_loss: 0.6937
Epoch 16/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4972 - loss: 0.8203 - val_f1: 0.4551 - val_loss: 0.6860
Epoch 17/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4983 - loss: 0.8111 - val_f1: 0.4551 - val_loss: 0.6912
Epoch 18/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - f1: 0.4592 - loss: 0.8182 - val_f1: 0.2245 - val_loss: 0.6984
Epoch 19/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - f1: 0.4504 - loss: 0.8175 - val_f1: 0.2245 - val_loss: 0.6950
Epoch 20/20
100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - f1: 0.4699 - loss: 0.8167 - val_f1: 0.4551 - val_loss: 0.6876